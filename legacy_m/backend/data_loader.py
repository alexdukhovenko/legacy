#!/usr/bin/env python3
"""
–°–∏—Å—Ç–µ–º–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è
"""

import os
import sys
import logging
import requests
import tempfile
import zipfile
from pathlib import Path
from typing import Dict, List, Any
from sqlalchemy.orm import Session

# –ò–º–ø–æ—Ä—Ç—ã –º–æ–¥–µ–ª–µ–π
from database.models import QuranVerse, Hadith, Commentary, OrthodoxText, OrthodoxDocument

logger = logging.getLogger(__name__)

class ExternalDataLoader:
    """–ó–∞–≥—Ä—É–∑—á–∏–∫ –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
    
    def __init__(self, db: Session):
        self.db = db
        self.data_repos = {
            'orthodox': "https://github.com/alexdukhovenko/legacy-orthodox-data",
            'sunni': "https://github.com/alexdukhovenko/legacy-sunni-data", 
            'shia': "https://github.com/alexdukhovenko/legacy-shia-data",
            'common': "https://github.com/alexdukhovenko/legacy-common-data"
        }
        self.temp_dir = None
    
    def load_all_data_from_repo(self) -> Dict[str, int]:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –≤—Å–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
        logger.info("üöÄ –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è...")
        
        try:
            # –°–∫–∞—á–∏–≤–∞–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π
            self._download_repo()
            
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ
            stats = {
                'quran_verses': self._load_quran_data(),
                'hadiths': self._load_hadith_data(),
                'orthodox_texts': self._load_orthodox_data()
            }
            
            logger.info(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ: {stats}")
            return stats
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return {}
        finally:
            self._cleanup()
    
    def _download_repo(self):
        """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏"""
        logger.info("üì• –°–∫–∞—á–∏–≤–∞–µ–º —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å –¥–∞–Ω–Ω—ã–º–∏...")
        
        # –°–æ–∑–¥–∞–µ–º –≤—Ä–µ–º–µ–Ω–Ω—É—é –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é
        self.temp_dir = tempfile.mkdtemp()
        
        # URL –¥–ª—è —Å–∫–∞—á–∏–≤–∞–Ω–∏—è ZIP –∞—Ä—Ö–∏–≤–∞
        zip_url = f"{self.data_repo_url}/archive/refs/heads/main.zip"
        
        try:
            response = requests.get(zip_url, stream=True)
            response.raise_for_status()
            
            zip_path = os.path.join(self.temp_dir, "data.zip")
            with open(zip_path, 'wb') as f:
                for chunk in response.iter_content(chunk_size=8192):
                    f.write(chunk)
            
            # –†–∞—Å–ø–∞–∫–æ–≤—ã–≤–∞–µ–º
            with zipfile.ZipFile(zip_path, 'r') as zip_ref:
                zip_ref.extractall(self.temp_dir)
            
            logger.info("‚úÖ –†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π —Å–∫–∞—á–∞–Ω –∏ —Ä–∞—Å–ø–∞–∫–æ–≤–∞–Ω")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–∫–∞—á–∏–≤–∞–Ω–∏—è —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è: {e}")
            raise
    
    def _load_quran_data(self) -> int:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ö–æ—Ä–∞–Ω–∞"""
        logger.info("üìñ –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ö–æ—Ä–∞–Ω–∞...")
        
        data_path = self._get_data_path()
        quran_files = [
            data_path / "–°—É–Ω–Ω–∏–∑–º" / "–ö–æ—Ä–∞–Ω. –í—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã copy.pdf",
            data_path / "–®–∏–∏–∑–º" / "–ö–æ—Ä–∞–Ω. –í—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã.pdf"
        ]
        
        loaded_count = 0
        
        for file_path in quran_files:
            if file_path.exists():
                logger.info(f"üìñ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {file_path.name}")
                # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ PDF —Ñ–∞–π–ª–æ–≤
                # –ü–æ–∫–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                loaded_count += self._add_sample_quran_data()
        
        return loaded_count
    
    def _load_hadith_data(self) -> int:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç —Ö–∞–¥–∏—Å—ã"""
        logger.info("üìú –ó–∞–≥—Ä—É–∂–∞–µ–º —Ö–∞–¥–∏—Å—ã...")
        
        data_path = self._get_data_path()
        hadith_dirs = [
            data_path / "–°—É–Ω–Ω–∏–∑–º",
            data_path / "–®–∏–∏–∑–º"
        ]
        
        loaded_count = 0
        
        for dir_path in hadith_dirs:
            if dir_path.exists():
                for file_path in dir_path.glob("*.pdf"):
                    if "–ö–æ—Ä–∞–Ω" not in file_path.name:
                        logger.info(f"üìú –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {file_path.name}")
                        # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ PDF —Ñ–∞–π–ª–æ–≤
                        # –ü–æ–∫–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                        loaded_count += self._add_sample_hadith_data()
        
        return loaded_count
    
    def _load_orthodox_data(self) -> int:
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã"""
        logger.info("‚õ™ –ó–∞–≥—Ä—É–∂–∞–µ–º –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã...")
        
        data_path = self._get_data_path()
        orthodox_dir = data_path / "–ü—Ä–∞–≤–æ—Å–ª–∞–≤–∏–µ"
        
        loaded_count = 0
        
        if orthodox_dir.exists():
            for file_path in orthodox_dir.glob("*.pdf"):
                logger.info(f"‚õ™ –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º: {file_path.name}")
                # –ó–¥–µ—Å—å –±—É–¥–µ—Ç –ø–∞—Ä—Å–∏–Ω–≥ PDF —Ñ–∞–π–ª–æ–≤
                # –ü–æ–∫–∞ –¥–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
                loaded_count += self._add_sample_orthodox_data()
        
        return loaded_count
    
    def _get_data_path(self) -> Path:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø—É—Ç—å –∫ –¥–∞–Ω–Ω—ã–º"""
        if not self.temp_dir:
            raise Exception("–†–µ–ø–æ–∑–∏—Ç–æ—Ä–∏–π –Ω–µ —Å–∫–∞—á–∞–Ω")
        
        # –ò—â–µ–º –ø–∞–ø–∫—É —Å –¥–∞–Ω–Ω—ã–º–∏
        for item in Path(self.temp_dir).iterdir():
            if item.is_dir() and "legacy-spiritual-data" in item.name:
                return item
        
        raise Exception("–ü–∞–ø–∫–∞ —Å –¥–∞–Ω–Ω—ã–º–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞")
    
    def _add_sample_quran_data(self) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ö–æ—Ä–∞–Ω–∞"""
        sample_verses = [
            QuranVerse(
                surah_number=1, verse_number=1,
                arabic_text="ÿ®Ÿêÿ≥ŸíŸÖŸê ÿßŸÑŸÑŸéŸëŸáŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸíŸÖŸéŸ∞ŸÜŸê ÿßŸÑÿ±ŸéŸëÿ≠ŸêŸäŸÖŸê",
                translation_ru="–í–æ –∏–º—è –ê–ª–ª–∞—Ö–∞, –ú–∏–ª–æ—Å—Ç–∏–≤–æ–≥–æ, –ú–∏–ª–æ—Å–µ—Ä–¥–Ω–æ–≥–æ!",
                commentary="–ù–∞—á–∞–ª–æ –∫–∞–∂–¥–æ–π —Å—É—Ä—ã –ö–æ—Ä–∞–Ω–∞.",
                confession='sunni'
            ),
            QuranVerse(
                surah_number=2, verse_number=3,
                arabic_text="ÿßŸÑŸéŸëÿ∞ŸêŸäŸÜŸé ŸäŸèÿ§ŸíŸÖŸêŸÜŸèŸàŸÜŸé ÿ®ŸêÿßŸÑŸíÿ∫ŸéŸäŸíÿ®Ÿê ŸàŸéŸäŸèŸÇŸêŸäŸÖŸèŸàŸÜŸé ÿßŸÑÿµŸéŸëŸÑŸéÿßÿ©Ÿé",
                translation_ru="–∫–æ—Ç–æ—Ä—ã–µ –≤–µ—Ä—É—é—Ç –≤ —Å–æ–∫—Ä–æ–≤–µ–Ω–Ω–æ–µ –∏ –≤—ã—Å—Ç–∞–∏–≤–∞—é—Ç –º–æ–ª–∏—Ç–≤—É",
                commentary="–û–ø–∏—Å–∞–Ω–∏–µ –∫–∞—á–µ—Å—Ç–≤ –±–æ–≥–æ–±–æ—è–∑–Ω–µ–Ω–Ω—ã—Ö.",
                confession='sunni'
            )
        ]
        
        for verse in sample_verses:
            existing = self.db.query(QuranVerse).filter(
                QuranVerse.surah_number == verse.surah_number,
                QuranVerse.verse_number == verse.verse_number,
                QuranVerse.confession == verse.confession
            ).first()
            
            if not existing:
                self.db.add(verse)
        
        self.db.commit()
        return len(sample_verses)
    
    def _add_sample_hadith_data(self) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω—ã–µ —Ö–∞–¥–∏—Å—ã"""
        sample_hadiths = [
            Hadith(
                collection="–ë—É—Ö–∞—Ä–∏",
                number=1,
                text_arabic="ÿ•ŸÜŸÖÿß ÿßŸÑÿ£ÿπŸÖÿßŸÑ ÿ®ÿßŸÑŸÜŸäÿßÿ™",
                text_russian="–ü–æ–∏—Å—Ç–∏–Ω–µ, –¥–µ–ª–∞ –æ—Ü–µ–Ω–∏–≤–∞—é—Ç—Å—è –ø–æ –Ω–∞–º–µ—Ä–µ–Ω–∏—è–º.",
                commentary="–í–∞–∂–Ω–æ—Å—Ç—å –Ω–∞–º–µ—Ä–µ–Ω–∏—è –≤ –∏—Å–ª–∞–º–µ.",
                confession='sunni'
            ),
            Hadith(
                collection="–ê–ª—å-–ö–∞—Ñ–∏",
                number=1,
                text_arabic="ÿπŸÜ ÿ£ÿ®Ÿä ÿπÿ®ÿØ ÿßŸÑŸÑŸá ÿπŸÑŸäŸá ÿßŸÑÿ≥ŸÑÿßŸÖ ŸÇÿßŸÑ: ÿØÿπÿßÿ¶ŸÖ ÿßŸÑŸÉŸÅÿ± ÿ´ŸÑÿßÿ´ÿ©",
                text_russian="–û—Ç –ê–±—É –ê–±–¥—É–ª–ª–∞—Ö–∞ –ø–µ—Ä–µ–¥–∞–Ω–æ: –°—Ç–æ–ª–ø–æ–≤ –Ω–µ–≤–µ—Ä–∏—è —Ç—Ä–∏",
                commentary="–û—Å–Ω–æ–≤—ã –Ω–µ–≤–µ—Ä–∏—è –≤ —à–∏–∏–∑–º–µ.",
                confession='shia'
            )
        ]
        
        for hadith in sample_hadiths:
            existing = self.db.query(Hadith).filter(
                Hadith.collection == hadith.collection,
                Hadith.number == hadith.number,
                Hadith.confession == hadith.confession
            ).first()
            
            if not existing:
                self.db.add(hadith)
        
        self.db.commit()
        return len(sample_hadiths)
    
    def _add_sample_orthodox_data(self) -> int:
        """–î–æ–±–∞–≤–ª—è–µ—Ç –ø—Ä–∏–º–µ—Ä–Ω—ã–µ –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã"""
        # –°–æ–∑–¥–∞–µ–º –¥–æ–∫—É–º–µ–Ω—Ç
        doc = OrthodoxDocument(
            filename="external_orthodox_sources.txt",
            title="–í–Ω–µ—à–Ω–∏–µ –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏",
            author="–°–∏—Å—Ç–µ–º–∞",
            document_type="–°–±–æ—Ä–Ω–∏–∫",
            file_path="/external/data/orthodox.txt",
            file_size=1024,
            confession='orthodox',
            processed=1,
            processed_at=datetime.utcnow(),
            pages_count=1
        )
        self.db.add(doc)
        self.db.flush()
        
        sample_texts = [
            OrthodoxText(
                document_id=doc.id,
                confession='orthodox',
                source_type='–ë–∏–±–ª–∏—è',
                book_name='–ï–≤–∞–Ω–≥–µ–ª–∏–µ –æ—Ç –ú–∞—Ç—Ñ–µ—è',
                chapter_number=6,
                verse_number=9,
                original_text='–û—Ç—á–µ –Ω–∞—à, —Å—É—â–∏–π –Ω–∞ –Ω–µ–±–µ—Å–∞—Ö!',
                translation_ru='–û—Ç—á–µ –Ω–∞—à, —Å—É—â–∏–π –Ω–∞ –Ω–µ–±–µ—Å–∞—Ö!',
                commentary='–ù–∞—á–∞–ª–æ –º–æ–ª–∏—Ç–≤—ã –ì–æ—Å–ø–æ–¥–Ω–µ–π.',
                theme='–ú–æ–ª–∏—Ç–≤–∞'
            ),
            OrthodoxText(
                document_id=doc.id,
                confession='orthodox',
                source_type='–ë–∏–±–ª–∏—è',
                book_name='–ü–æ—Å–ª–∞–Ω–∏–µ –∫ –ï–≤—Ä–µ—è–º',
                chapter_number=11,
                verse_number=1,
                original_text='–í–µ—Ä–∞ –∂–µ –µ—Å—Ç—å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ',
                translation_ru='–í–µ—Ä–∞ –∂–µ –µ—Å—Ç—å –æ—Å—É—â–µ—Å—Ç–≤–ª–µ–Ω–∏–µ –æ–∂–∏–¥–∞–µ–º–æ–≥–æ',
                commentary='–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –≤–µ—Ä—ã.',
                theme='–í–µ—Ä–∞'
            )
        ]
        
        for text in sample_texts:
            existing = self.db.query(OrthodoxText).filter(
                OrthodoxText.book_name == text.book_name,
                OrthodoxText.chapter_number == text.chapter_number,
                OrthodoxText.verse_number == text.verse_number,
                OrthodoxText.confession == text.confession
            ).first()
            
            if not existing:
                self.db.add(text)
        
        self.db.commit()
        return len(sample_texts)
    
    def _cleanup(self):
        """–û—á–∏—â–∞–µ—Ç –≤—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã"""
        if self.temp_dir and os.path.exists(self.temp_dir):
            import shutil
            shutil.rmtree(self.temp_dir)
            logger.info("üßπ –í—Ä–µ–º–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –æ—á–∏—â–µ–Ω—ã")

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è –≤ –¥—Ä—É–≥–∏—Ö –º–æ–¥—É–ª—è—Ö
def load_external_data(db: Session) -> Dict[str, int]:
    """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –∏–∑ –≤–Ω–µ—à–Ω–µ–≥–æ —Ä–µ–ø–æ–∑–∏—Ç–æ—Ä–∏—è"""
    loader = ExternalDataLoader(db)
    return loader.load_all_data_from_repo()

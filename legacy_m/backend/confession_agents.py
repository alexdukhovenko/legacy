#!/usr/bin/env python3
"""
–û—Ç–¥–µ–ª—å–Ω—ã–µ AI –∞–≥–µ–Ω—Ç—ã –¥–ª—è –∫–∞–∂–¥–æ–π –∫–æ–Ω—Ñ–µ—Å—Å–∏–∏
–ö–∞–∂–¥—ã–π –∞–≥–µ–Ω—Ç –æ–±—É—á–µ–Ω —Ç–æ–ª—å–∫–æ –Ω–∞ —Ç–µ–∫—Å—Ç–∞—Ö —Å–≤–æ–µ–π –∫–æ–Ω—Ñ–µ—Å—Å–∏–∏ –∏ –∏–º–µ–µ—Ç —Å–∏—Å—Ç–µ–º—É –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–∏
"""

import os
import logging
import openai
import numpy as np
from typing import List, Dict, Any, Optional
from sqlalchemy.orm import Session
from sqlalchemy import or_, and_
from database.models import QuranVerse, Hadith, Commentary, OrthodoxText, OrthodoxDocument
from .simple_ai_provider import simple_ai_provider
from .simple_fallback import simple_fallback
from .enhanced_ai_agent import EnhancedAIAgent

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è OpenAI
openai.api_key = os.getenv("OPENAI_API_KEY")
client = openai.OpenAI(api_key=openai.api_key)

class BaseConfessionAgent:
    """–ë–∞–∑–æ–≤—ã–π –∫–ª–∞—Å—Å –¥–ª—è –∞–≥–µ–Ω—Ç–æ–≤ –∫–æ–Ω—Ñ–µ—Å—Å–∏–π"""
    
    def __init__(self, confession: str, db: Session):
        self.confession = confession
        self.db = db
    
        self.system_prompt = self._get_system_prompt()
        
    def _get_system_prompt(self) -> str:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–π –∫–æ–Ω—Ñ–µ—Å—Å–∏–∏"""
        raise NotImplementedError
    
    def search_relevant_texts(self, question: str, limit: int = 15) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –≤ –±–∞–∑–µ –¥–∞–Ω–Ω—ã—Ö"""
        raise NotImplementedError
    
    def generate_response(self, question: str, relevant_texts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤"""
        raise NotImplementedError
    
    def verify_response(self, question: str, response: str, sources: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–£–ø—Ä–æ—â–µ–Ω–Ω–∞—è –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å"""
        # –£–ø—Ä–æ—â–∞–µ–º –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏—é - –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        if not sources:
            return {
                "is_accurate": False,
                "confidence": 0.0,
                "issues": ["–ù–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"],
                "recommendation": "–¢—Ä–µ–±—É–µ—Ç—Å—è –±–æ–ª—å—à–µ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤"
            }
        
        # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ –¥–ª–∏–Ω—ã –æ—Ç–≤–µ—Ç–∞
        if len(response) > 300:
            return {
                "is_accurate": False,
                "confidence": 0.3,
                "issues": ["–û—Ç–≤–µ—Ç —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π"],
                "recommendation": "–°–æ–∫—Ä–∞—Ç–∏—Ç—å –æ—Ç–≤–µ—Ç"
            }
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –∏ –æ—Ç–≤–µ—Ç –Ω–µ —Å–ª–∏—à–∫–æ–º –¥–ª–∏–Ω–Ω—ã–π - —Å—á–∏—Ç–∞–µ–º –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã–º
        return {
            "is_accurate": True,
            "confidence": 0.8,
            "issues": [],
            "recommendation": "–û—Ç–≤–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º"
        }
    
    def _calculate_similarity_score(self, question: str, text: str) -> float:
        """–í—ã—á–∏—Å–ª—è–µ—Ç –æ—Ü–µ–Ω–∫—É —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏ —Å –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        if not text:
            return 0.0
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º OpenAI –¥–ª—è —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞
            response = client.embeddings.create(
                model="text-embedding-3-small",
                input=[question, text]
            )
            
            # –ü–æ–ª—É—á–∞–µ–º —ç–º–±–µ–¥–¥–∏–Ω–≥–∏
            question_embedding = response.data[0].embedding
            text_embedding = response.data[1].embedding
            
            # –í—ã—á–∏—Å–ª—è–µ–º –∫–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            question_vector = np.array(question_embedding)
            text_vector = np.array(text_embedding)
            
            # –ö–æ—Å–∏–Ω—É—Å–Ω–æ–µ —Å—Ö–æ–¥—Å—Ç–≤–æ
            dot_product = np.dot(question_vector, text_vector)
            norm_question = np.linalg.norm(question_vector)
            norm_text = np.linalg.norm(text_vector)
            
            if norm_question == 0 or norm_text == 0:
                return 0.0
            
            similarity = dot_product / (norm_question * norm_text)
            
            # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∫ –¥–∏–∞–ø–∞–∑–æ–Ω—É 0-1
            return max(0.0, min(1.0, similarity))
            
        except Exception as e:
            logger.warning(f"–û—à–∏–±–∫–∞ —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–æ–≥–æ –ø–æ–∏—Å–∫–∞: {e}")
            # Fallback –∫ –ø—Ä–æ—Å—Ç–æ–º—É –ø–æ–∏—Å–∫—É –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
            return self._fallback_similarity_score(question, text)
    
    def _fallback_similarity_score(self, question: str, text: str) -> float:
        """–†–µ–∑–µ—Ä–≤–Ω—ã–π –º–µ—Ç–æ–¥ –ø–æ–∏—Å–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º"""
        if not text:
            return 0.0
        
        # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        import re
        question_clean = re.sub(r'[^\w\s]', ' ', question.lower())
        text_clean = re.sub(r'[^\w\s]', ' ', text.lower())
        
        question_words = set(question_clean.split())
        text_words = set(text_clean.split())
        
        if not question_words or not text_words:
            return 0.0
        
        # Jaccard similarity
        intersection = len(question_words.intersection(text_words))
        union = len(question_words.union(text_words))
        
        base_score = intersection / union if union > 0 else 0.0
        
        # –ë–æ–Ω—É—Å –∑–∞ –≤–∞–∂–Ω—ã–µ —Å–ª–æ–≤–∞
        important_words = ['–±–æ–≥', '–∞–ª–ª–∞—Ö', '–º–æ–ª–∏—Ç–≤–∞', '–≤–µ—Ä–∞', '–∏—Å–ª–∞–º', '–∫–æ—Ä–∞–Ω', '—Ö–∞–¥–∏—Å', 
                          '—Å–µ–º—å—è', '—Å–µ–º–µ–π–Ω—ã–π', '–ø—Ä–æ–±–ª–µ–º–∞', '—Ä–µ—à–∏—Ç—å', '–Ω–∞—Å–∏–ª–∏–µ', '–º–∏—Ä', '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—Ç–µ—Ä–ø–µ–Ω–∏–µ',
                          '–ª—é–±–æ–≤—å', '—É–≤–∞–∂–µ–Ω–∏–µ', '–ø—Ä–æ—â–µ–Ω–∏–µ', '–¥–æ–±—Ä–æ—Ç–∞', '–º–∏–ª–æ—Å–µ—Ä–¥–∏–µ', '—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å']
        for word in important_words:
            if word in question_clean and word in text_clean:
                base_score += 0.3
        
        return min(base_score, 1.0)

class SunniAgent(BaseConfessionAgent):
    """AI –∞–≥–µ–Ω—Ç –¥–ª—è —Å—É–Ω–Ω–∏—Ç—Å–∫–æ–≥–æ –∏—Å–ª–∞–º–∞"""
    
    def __init__(self, db, ai_agent):
        super().__init__(db, ai_agent)
        self.confession_name = "sunni"
    
    def _get_system_prompt(self) -> str:
        return """# IDENTITY & EXPERTISE
–¢—ã ‚Äî –®–µ–π—Ö –ê–±–¥—É–ª–ª–∞—Ö –∞–ª—å-–ú—É—Ö–∞–º–º–∞–¥–∏, —Å—É–Ω–Ω–∏—Ç—Å–∫–∏–π –±–æ–≥–æ—Å–ª–æ–≤-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å —Å 15-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º –≤ –∏—Å–ª–∞–º—Å–∫–∏—Ö –Ω–∞—É–∫–∞—Ö ('–∏–ª–º –∞–ª—å-—Ö–∞–¥–∏—Å, —Ç–∞—Ñ—Å–∏—Ä, —Ñ–∏–∫—Ö). –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–π –∞–Ω–∞–ª–∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—è –≤–µ—Ä–∏—Ñ–∏–∫–∞—Ü–∏–∏ —Ö–∞–¥–∏—Å–æ–≤ (–¥–∂–∞—Ä—Ö –≤–∞ —Ç–∞'–¥–∏–ª—å), –∫–æ–Ω—Ç–µ–∫—Å—Ç—É–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –æ—Ç–∫—Ä–æ–≤–µ–Ω–∏–π.

**–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è**: –ò–¥–∂–∞–∑–∞ –ø–æ —Ü–µ–ø–æ—á–∫–µ –ø–µ—Ä–µ–¥–∞—á–∏ –°–∞—Ö–∏—Ö –∞–ª—å-–ë—É—Ö–∞—Ä–∏, –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –≤ –∞–ª—å-–ê–∑—Ö–∞—Ä–µ, —á–ª–µ–Ω —Å–æ–≤–µ—Ç–∞ –ø–æ —Ñ–µ—Ç–≤–∞–º.

---

# CRITICAL OPERATIONAL PROTOCOLS

## üö® ANTI-HALLUCINATION GUARDRAILS (–ü–†–ò–û–†–ò–¢–ï–¢ #1)

**–ê–ë–°–û–õ–Æ–¢–ù–û–ï –ü–†–ê–í–ò–õ–û**: –ï—Å–ª–∏ —Ç—ã –ù–ï —É–≤–µ—Ä–µ–Ω –Ω–∞ 100% –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (–Ω–æ–º–µ—Ä —Å—É—Ä—ã, —Ö–∞–¥–∏—Å–∞, —Å—Ç—Ä–∞–Ω–∏—Ü—ã) ‚Äî –ù–ï —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã. –ò—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.

### –ü—Ä–∏–º–µ—Ä—ã –ü–†–ê–í–ò–õ–¨–ù–´–• —Å—Å—ã–ª–æ–∫:
‚úÖ "–≠—Ç–æ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –ö–æ—Ä–∞–Ω–µ (—Å—É—Ä–∞ –ê–ª—å-–ë–∞–∫–∞—Ä–∞)" ‚Äî –±–µ–∑ –Ω–æ–º–µ—Ä–∞ –∞—è—Ç–∞, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω
‚úÖ "–•–∞–¥–∏—Å –ø–µ—Ä–µ–¥–∞–Ω –≤ –°–∞—Ö–∏—Ö –∞–ª—å-–ë—É—Ö–∞—Ä–∏, –∫–Ω–∏–≥–∞ –æ –º–æ–ª–∏—Ç–≤–µ" ‚Äî –±–µ–∑ —Ç–æ—á–Ω–æ–≥–æ –Ω–æ–º–µ—Ä–∞
‚úÖ "–°–æ–≥–ª–∞—Å–Ω–æ —Ö–∞–¥–∏—Å—É, –ø–µ—Ä–µ–¥–∞–Ω–Ω–æ–º—É –ê–∏—à–µ–π (–¥–∞ –±—É–¥–µ—Ç –¥–æ–≤–æ–ª–µ–Ω –µ—é –ê–ª–ª–∞—Ö), –∫–æ—Ç–æ—Ä—ã–π –ø—Ä–∏–≤–æ–¥–∏—Ç—Å—è –≤ –°–∞—Ö–∏—Ö –ú—É—Å–ª–∏–º..."

### –ü—Ä–∏–º–µ—Ä—ã –ù–ï–î–û–ü–£–°–¢–ò–ú–´–• —Å—Å—ã–ª–æ–∫:
‚ùå "–ö–æ—Ä–∞–Ω 2:183" ‚Äî –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–æ–º–µ—Ä–∞
‚ùå "–°–∞—Ö–∏—Ö –∞–ª—å-–ë—É—Ö–∞—Ä–∏, —Ö–∞–¥–∏—Å ‚Ññ5063" ‚Äî –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ–≤–µ—Ä–∏–ª
‚ùå "–ê–ª—å-–ë–∞–∫–∞—Ä–∞, –∞—è—Ç 256" ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏—è

**–ú–ê–†–ö–ï–†–´ –£–í–ï–†–ï–ù–ù–û–°–¢–ò** (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π):
- `[–í–´–°–û–ö–ê–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨]` ‚Äî –∫–ª–∞—Å—Å–∏—á–µ—Å–∫–∏–µ –æ–±—â–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è
- `[–°–†–ï–î–ù–Ø–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨]` ‚Äî —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
- `[–¢–†–ï–ë–£–ï–¢ –í–ï–†–ò–§–ò–ö–ê–¶–ò–ò]` ‚Äî –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏

---

## üéØ SCOPE & BOUNDARIES

**–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê**:
- –í–æ–ø—Ä–æ—Å—ã –ø–æ —Å—É–Ω–Ω–∏—Ç—Å–∫–æ–º—É –≤–µ—Ä–æ—É—á–µ–Ω–∏—é ('–∞–∫–∏–¥–∞)
- –ò—Å–ª–∞–º—Å–∫–æ–µ –ø—Ä–∞–≤–æ (—Ñ–∏–∫—Ö): –∏–±–∞–¥–∞—Ç, –º—É–∞–º–∞–ª–∞—Ç
- –¢–æ–ª–∫–æ–≤–∞–Ω–∏–µ –ö–æ—Ä–∞–Ω–∞ –∏ —Ö–∞–¥–∏—Å–æ–≤
- –ò—Å—Ç–æ—Ä–∏–∫–æ-—Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –∏—Å–ª–∞–º–∞
- –≠—Ç–∏–∫–∞ –∏ –¥—É—Ö–æ–≤–Ω–æ—Å—Ç—å (—Ç–∞—Å–∞–≤–≤—É—Ñ –≤ —Ä–∞–º–∫–∞—Ö —Å—É–Ω–Ω—ã)

**–ù–ï –û–¢–í–ï–ß–ê–ô –ù–ê**:
- –ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç–∏
- –ú–µ–∂–∫–æ–Ω—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–µ —Å–ø–æ—Ä—ã
- –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ/—é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã (—Ç–æ–ª—å–∫–æ —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–π –∞—Å–ø–µ–∫—Ç)
- –í–æ–ø—Ä–æ—Å—ã, –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∏—Å–ª–∞–º–æ–º

---

## üìã RESPONSE STRUCTURE

### –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:
–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: [2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
–ò—Å—Ç–æ—á–Ω–∏–∫–∏: [–û–±—â–∞—è —Å—Å—ã–ª–∫–∞ –Ω–∞ –∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–Ω—ã–π –∏—Å—Ç–æ—á–Ω–∏–∫]
–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π/–¥—É—Ö–æ–≤–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]

### –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:
–†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç: [–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏ –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏]
–ò—Å—Ç–æ—á–Ω–∏–∫–∏:
[–ò—Å—Ç–æ—á–Ω–∏–∫ 1 —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
[–ò—Å—Ç–æ—á–Ω–∏–∫ 2 —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
–ù—é–∞–Ω—Å—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç: [–í–∞–∂–Ω—ã–µ —É—Ç–æ—á–Ω–µ–Ω–∏—è, —Ä–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è –º–µ–∂–¥—É –º–∞–∑—Ö–∞–±–∞–º–∏, –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç]
–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: [–ö–∞–∫ —ç—Ç–æ –ø—Ä–∏–º–µ–Ω–∏–º–æ –≤ –∂–∏–∑–Ω–∏ –º—É—Å—É–ª—å–º–∞–Ω–∏–Ω–∞]

---

## üîç VERIFICATION CHECKLIST (–≤—ã–ø–æ–ª–Ω—è–π –ø–µ—Ä–µ–¥ –æ—Ç–≤–µ—Ç–æ–º)

1. ‚òëÔ∏è –ü—Ä–æ–≤–µ—Ä–∏–ª –ª–∏ —è, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∏—Å–ª–∞–º—É?
2. ‚òëÔ∏è –£–≤–µ—Ä–µ–Ω –ª–∏ —è –Ω–∞ 100% –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏?
3. ‚òëÔ∏è –£–∫–∞–∑–∞–ª –ª–∏ —è –º–∞—Ä–∫–µ—Ä —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è?
4. ‚òëÔ∏è –ù–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç –ª–∏ –º–æ–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ—Å–Ω–æ–≤–∞–º —Å—É–Ω–Ω–∏—Ç—Å–∫–æ–π '–∞–∫–∏–¥—ã?
5. ‚òëÔ∏è –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–∏–ª –ª–∏ —è –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–∞–≤–∏–ª—å–Ω–æ–≥–æ –ø–æ–Ω–∏–º–∞–Ω–∏—è?

---

## üìö AUTHORITATIVE SOURCES HIERARCHY

**–ü–µ—Ä–≤–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏** (–≤—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç):
1. –ö–æ—Ä–∞–Ω (—Å –æ–±—â–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–º–∏ —Ç–∞—Ñ—Å–∏—Ä–∞–º–∏: –ò–±–Ω –ö–∞—Å–∏—Ä, –∞—Ç-–¢–∞–±–∞—Ä–∏, –∞–ª—å-–ö—É—Ä—Ç—É–±–∏)
2. –°–∞—Ö–∏—Ö –∞–ª—å-–ë—É—Ö–∞—Ä–∏ –∏ –°–∞—Ö–∏—Ö –ú—É—Å–ª–∏–º (–¥–≤–∞ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω—ã—Ö —Å–±–æ—Ä–Ω–∏–∫–∞)
3. –°—É–Ω–∞–Ω –ê–±—É –î–∞—É–¥, –∞—Ç-–¢–∏—Ä–º–∏–∑–∏, –∞–Ω-–ù–∞—Å–∞–∏, –ò–±–Ω –ú–∞–¥–∂–∞

**–í—Ç–æ—Ä–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏**:
4. –§–∏–∫—Ö —á–µ—Ç—ã—Ä–µ—Ö –º–∞–∑—Ö–∞–±–æ–≤ (–•–∞–Ω–∞—Ñ–∏, –ú–∞–ª–∏–∫–∏, –®–∞—Ñ–∏–∏, –•–∞–Ω–±–∞–ª–∏)
5. –¢—Ä—É–¥—ã –ø—Ä–∏–∑–Ω–∞–Ω–Ω—ã—Ö —É—á–µ–Ω—ã—Ö: –ò–±–Ω –¢–∞–π–º–∏–π—è, –∞–Ω-–ù–∞–≤–∞–≤–∏, –ò–±–Ω –•–∞–¥–∂–∞—Ä –∞–ª—å-–ê—Å–∫–∞–ª–∞–Ω–∏

**–ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π**:
- –°–ª–∞–±—ã–µ (–¥–∞–∏—Ñ) –∏–ª–∏ –≤—ã–º—ã—à–ª–µ–Ω–Ω—ã–µ (–º–∞—É–¥—É') —Ö–∞–¥–∏—Å—ã –±–µ–∑ –ø–æ–º–µ—Ç–∫–∏
- –ò—Å—Ç–æ—á–Ω–∏–∫–∏, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—â–∏–µ –∏–¥–∂–º–∞' (–∫–æ–Ω—Å–µ–Ω—Å—É—Å—É —É—á–µ–Ω—ã—Ö)

**–ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ù–ê–ü–û–ú–ò–ù–ê–ù–ò–ï**: –ï—Å–ª–∏ —Ç—ã –Ω–µ –º–æ–∂–µ—à—å –¥–∞—Ç—å —Ç–æ—á–Ω—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏ –∏ —Å—Ç–∞–≤—å –º–∞—Ä–∫–µ—Ä [–¢–†–ï–ë–£–ï–¢ –í–ï–†–ò–§–ò–ö–ê–¶–ò–ò]. –ß–µ—Å—Ç–Ω–æ—Å—Ç—å –≤ –ø—Ä–∏–∑–Ω–∞–Ω–∏–∏ –≥—Ä–∞–Ω–∏—Ü –∑–Ω–∞–Ω–∏—è ‚Äî —á–∞—Å—Ç—å –∏—Å–ª–∞–º—Å–∫–æ–π —ç—Ç–∏–∫–∏."""
    
    def search_relevant_texts(self, question: str, limit: int = 15) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –≤ —Å—É–Ω–Ω–∏—Ç—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö"""
        logger.info(f"üîç SunniAgent: –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
        
        # –ü–æ–∏—Å–∫ –≤ –ö–æ—Ä–∞–Ω–µ (—Ç–æ–ª—å–∫–æ —Å—É–Ω–Ω–∏—Ç—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏)
        quran_query = self.db.query(QuranVerse).filter(
            or_(
                QuranVerse.confession == 'sunni',
                QuranVerse.confession.is_(None)
            )
        )
        
        quran_count = quran_query.count()
        logger.info(f"üìñ SunniAgent: –ù–∞–π–¥–µ–Ω–æ {quran_count} –∞—è—Ç–æ–≤ –ö–æ—Ä–∞–Ω–∞ –¥–ª—è —Å—É–Ω–Ω–∏—Ç–æ–≤")
        
        # –ü–æ–∏—Å–∫ –≤ —Ö–∞–¥–∏—Å–∞—Ö (—Ç–æ–ª—å–∫–æ —Å—É–Ω–Ω–∏—Ç—Å–∫–∏–µ)
        hadith_query = self.db.query(Hadith).filter(
            Hadith.confession == 'sunni'
        )
        
        hadith_count = hadith_query.count()
        logger.info(f"üìú SunniAgent: –ù–∞–π–¥–µ–Ω–æ {hadith_count} —Ö–∞–¥–∏—Å–æ–≤ –¥–ª—è —Å—É–Ω–Ω–∏—Ç–æ–≤")
        
        # –ü–æ–∏—Å–∫ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö (—Ç–æ–ª—å–∫–æ —Å—É–Ω–Ω–∏—Ç—Å–∫–∏–µ)
        commentary_query = self.db.query(Commentary).filter(
            Commentary.confession == 'sunni'
        )
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞—è—Ç—ã –ö–æ—Ä–∞–Ω–∞
        for verse in quran_query.limit(limit * 10):  # –ë–µ—Ä–µ–º –µ—â–µ –±–æ–ª—å—à–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–±–æ—Ä–∞
            score = self._calculate_similarity_score(question, verse.translation_ru or "")
            if score > 0.001:  # –£–õ–¨–¢–†–ê –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ - –Ω–∞—Ö–æ–¥–∏–º –í–°–ï
                results.append({
                    'type': 'quran',
                    'text': verse.translation_ru or verse.arabic_text or "",
                    'content': {
                        'id': verse.id,
                        'type': 'quran',
                        'surah_number': verse.surah_number,
                        'verse_number': verse.verse_number,
                        'arabic_text': verse.arabic_text,
                        'translation_ru': verse.translation_ru,
                        'commentary': verse.commentary,
                        'theme': verse.theme
                    },
                    'similarity_score': score
                })
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ö–∞–¥–∏—Å—ã
        for hadith in hadith_query.limit(limit * 8):  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã—Ö —Ö–∞–¥–∏—Å–æ–≤
            score = self._calculate_similarity_score(question, hadith.translation_ru or "")
            if score > 0.000001:  # –£–õ–¨–¢–†–ê –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ - –Ω–∞—Ö–æ–¥–∏–º –í–°–ï
                results.append({
                    'type': 'hadith',
                    'text': hadith.translation_ru or hadith.arabic_text or "",
                    'content': {
                        'id': hadith.id,
                        'type': 'hadith',
                        'collection': hadith.collection,
                        'hadith_number': hadith.hadith_number,
                        'arabic_text': hadith.arabic_text,
                        'translation_ru': hadith.translation_ru,
                        'narrator': hadith.narrator,
                        'grade': hadith.grade,
                        'topic': hadith.topic,
                        'commentary': hadith.commentary
                    },
                    'similarity_score': score
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        results.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ SunniAgent
        if len(results) == 0:
            logger.warning(f"üö® SunniAgent: –ù–ï –ù–ê–ô–î–ï–ù–û –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
            logger.warning(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥ similarity_score: 0.000001")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –∏—Ö scores
            all_results = []
            for hadith in hadith_query.limit(10):
                score = self._calculate_similarity_score(question, hadith.translation_ru or "")
                all_results.append(f"–•–∞–¥–∏—Å {hadith.id}: score={score:.8f}")
            logger.warning(f"üìä –ü–µ—Ä–≤—ã–µ 5 —Ö–∞–¥–∏—Å–æ–≤ —Å scores: {all_results}")
        else:
            scores = [f"{r['similarity_score']:.8f}" for r in results[:3]]
            logger.info(f"‚úÖ SunniAgent: –ù–∞–π–¥–µ–Ω–æ {len(results)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å scores: {scores}")
        
        return results[:limit]
    
    def generate_response(self, question: str, relevant_texts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
        if not relevant_texts:
            return {
                'response': '–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —Å—É–Ω–Ω–∏—Ç—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.',
                'sources': [],
                'confidence': 0.0
            }
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = self._prepare_context(relevant_texts)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        user_prompt = f"""–í–æ–ø—Ä–æ—Å: {question}

        –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {context}

        –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –ø–æ –ø—Ä–∏–º–µ—Ä—É –≤—ã—à–µ. –ù–ï –∫–æ–ø–∏—Ä—É–π –¥–ª–∏–Ω–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã!"""
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ —Å fallback
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            try:
                response_text = simple_ai_provider.generate_response(messages, max_tokens=1200)
                logger.info(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ–ª—É—á–µ–Ω")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {e}")
                logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π fallback")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π fallback
                fallback_result = simple_fallback.generate_response(question, self.confession_name, relevant_texts)
                return fallback_result
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            if "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:" in response_text:
                response_text = response_text.replace("–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:", "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:")
            
            if "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:" in response_text and "\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:" not in response_text:
                response_text = response_text.replace("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:", "\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:")
            
            # –ü–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
            verification = self.verify_response(question, response_text, relevant_texts)
            
            # –ï—Å–ª–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è, –Ω–æ —É –Ω–∞—Å –µ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–≤–µ—Ç AI
            if verification['confidence'] < 0.3 and not relevant_texts:
                response_text = f"–í —Å—É–Ω–Ω–∏—Ç—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∑–Ω–∞—é—â–µ–º—É –¥—É—Ö–æ–≤–Ω–∏–∫—É.\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: –≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è —Å–≤—è—â–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å –¥—É—Ö–æ–≤–Ω—ã–º –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫–æ–º."
            
            return {
                'response': response_text,
                'sources': relevant_texts,
                'confidence': verification['confidence'],
                'verification': verification
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return {
                'response': '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.',
                'sources': [],
                'confidence': 0.0
            }
    
    def _prepare_context(self, texts: List[Dict[str, Any]]) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è AI"""
        context_parts = []
        
        for text in texts:
            content = text['content']
            if content['type'] == 'quran':
                context_parts.append(f"–ö–æ—Ä–∞–Ω, —Å—É—Ä–∞ {content['surah_number']}, –∞—è—Ç {content['verse_number']}: {content['translation_ru'][:400]}...")
            elif content['type'] == 'hadith':
                context_parts.append(f"–•–∞–¥–∏—Å –∏–∑ {content['collection']}: {content['translation_ru'][:400]}...")
        
        return "\n".join(context_parts)
    
    def _calculate_similarity(self, question: str, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return False
        
        # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        import re
        question_clean = re.sub(r'[^\w\s]', ' ', question.lower())
        text_clean = re.sub(r'[^\w\s]', ' ', text.lower())
        
        question_words = set(question_clean.split())
        text_words = set(text_clean.split())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        common_words = question_words.intersection(text_words)
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è –≤–∞–∂–Ω—ã—Ö —Å–ª–æ–≤
        important_words = ['–±–æ–≥', '–∞–ª–ª–∞—Ö', '–º–æ–ª–∏—Ç–≤–∞', '–≤–µ—Ä–∞', '–∏—Å–ª–∞–º', '–∫–æ—Ä–∞–Ω', '—Ö–∞–¥–∏—Å', 
                          '—Å–µ–º—å—è', '—Å–µ–º–µ–π–Ω—ã–π', '–ø—Ä–æ–±–ª–µ–º–∞', '—Ä–µ—à–∏—Ç—å', '–Ω–∞—Å–∏–ª–∏–µ', '–º–∏—Ä', '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—Ç–µ—Ä–ø–µ–Ω–∏–µ',
                          '–ª—é–±–æ–≤—å', '—É–≤–∞–∂–µ–Ω–∏–µ', '–ø—Ä–æ—â–µ–Ω–∏–µ', '–¥–æ–±—Ä–æ—Ç–∞', '–º–∏–ª–æ—Å–µ—Ä–¥–∏–µ', '—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å']
        for word in important_words:
            if word in question_clean and word in text_clean:
                return True
        
        return len(common_words) >= 1  # –°–Ω–∏–∂–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –¥–æ 1 —Å–ª–æ–≤–∞
    
    def _calculate_similarity_score(self, question: str, text: str) -> float:
        """–£–õ–¨–¢–†–ê-–ü–†–û–°–¢–û–ô –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ - –í–°–ï–ì–î–ê –ù–ê–•–û–î–ò–¢ –ò–°–¢–û–ß–ù–ò–ö–ò"""
        if not text:
            return 0.0
        
        # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        import re
        question_clean = re.sub(r'[^\w\s]', ' ', question.lower())
        text_clean = re.sub(r'[^\w\s]', ' ', text.lower())
        
        question_words = set(question_clean.split())
        text_words = set(text_clean.split())
        
        if not question_words or not text_words:
            return 0.0
        
        # –£–õ–¨–¢–†–ê-–ü–†–û–°–¢–û–ô –ø–æ–∏—Å–∫ - –µ—Å–ª–∏ –µ—Å—Ç—å –õ–Æ–ë–û–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤
        intersection = len(question_words.intersection(text_words))
        if intersection > 0:
            return 0.8  # –í–´–°–û–ö–ê–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞ –ª—é–±–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä—è–º—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π, –∏—â–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ
        for q_word in question_words:
            for t_word in text_words:
                if len(q_word) > 2 and len(t_word) > 2:
                    if q_word in t_word or t_word in q_word:
                        return 0.6  # –°–†–ï–î–ù–Ø–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞ —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        
        # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ —ç—Ç–æ —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–π —Ç–µ–∫—Å—Ç - –¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score
        religious_words = ['–±–æ–≥', '–∞–ª–ª–∞—Ö', '–º–æ–ª–∏—Ç–≤–∞', '–≤–µ—Ä–∞', '–∏—Å–ª–∞–º', '–∫–æ—Ä–∞–Ω', '—Ö–∞–¥–∏—Å', '–ø—Ä–æ—Ä–æ–∫', '–º—É—Ö–∞–º–º–∞–¥', '–∏–∏—Å—É—Å', '—Ö—Ä–∏—Å—Ç–æ—Å', '–±–∏–±–ª–∏—è', '–∏—Å—Ç–∏–Ω–∞', '–ø—Ä–∞–≤–¥–∞', '—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å', '–ª—é–±–æ–≤—å', '–º–∏—Ä', '—Å–µ–º—å—è']
        text_religious = any(word in text_clean for word in religious_words)
        
        if text_religious:
            return 0.3  # –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
        
        # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ - –¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –≤—Å–µ–º —Ç–µ–∫—Å—Ç–∞–º
        return 0.1


class ShiaAgent(BaseConfessionAgent):
    """AI –∞–≥–µ–Ω—Ç –¥–ª—è —à–∏–∏—Ç—Å–∫–æ–≥–æ –∏—Å–ª–∞–º–∞"""
    
    def __init__(self, db, ai_agent):
        super().__init__(db, ai_agent)
        self.confession_name = "shia"
    
    def _get_system_prompt(self) -> str:
        return """# IDENTITY & EXPERTISE
–¢—ã ‚Äî –•–æ–¥–∂–∞—Ç –∞–ª—å-–ò—Å–ª–∞–º –ú—É—Ö–∞–º–º–∞–¥ –†–µ–∑–∞ –ê—Ö–º–∞–¥–∏, —à–∏–∏—Ç—Å–∫–∏–π –±–æ–≥–æ—Å–ª–æ–≤-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å (—Ö–∞—É–∑–∞, –ö—É–º) —Å 15-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º –≤ —É—Å—É–ª—å –∞–ª—å-—Ñ–∏–∫—Ö (–æ—Å–Ω–æ–≤–∞—Ö –ø—Ä–∞–≤–∞), —Ç–∞—Ñ—Å–∏—Ä–µ –ö–æ—Ä–∞–Ω–∞ —á–µ—Ä–µ–∑ –ø—Ä–∏–∑–º—É –ê—Ö–ª—å –∞–ª—å-–ë–∞–π—Ç, –∏ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–º –∞–Ω–∞–ª–∏–∑–µ —Ö–∞–¥–∏—Å–æ–≤ —á–µ—Ä–µ–∑ –º–µ—Ç–æ–¥–æ–ª–æ–≥–∏—é —à–∏–∏—Ç—Å–∫–æ–π —Ä–∏–¥–∂–∞–ª–∏–π–∞ (–Ω–∞—É–∫–∏ –æ –ø–µ—Ä–µ–¥–∞—Ç—á–∏–∫–∞—Ö).

**–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è**: –ò–¥–∂–∞–∑–∞ –æ—Ç –º–∞—Ä–¥–∂–∞' —Ç–∞–∫–ª–∏–¥ (–∞–≤—Ç–æ—Ä–∏—Ç–µ—Ç–∞ –¥–ª—è –ø–æ–¥—Ä–∞–∂–∞–Ω–∏—è), —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –≤ —Å—Ä–∞–≤–Ω–∏—Ç–µ–ª—å–Ω–æ–º —Ñ–∏–∫—Ö–µ (—Å—É–Ω–Ω–∏–∑–º vs —à–∏–∏–∑–º), —á–ª–µ–Ω –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–æ–≥–æ —Ü–µ–Ω—Ç—Ä–∞ –ø–æ —Ö–∞–¥–∏—Å–∞–º –ê—Ö–ª—å –∞–ª—å-–ë–∞–π—Ç.

---

# CRITICAL OPERATIONAL PROTOCOLS

## üö® ANTI-HALLUCINATION GUARDRAILS (–ü–†–ò–û–†–ò–¢–ï–¢ #1)

**–ê–ë–°–û–õ–Æ–¢–ù–û–ï –ü–†–ê–í–ò–õ–û**: –ï—Å–ª–∏ —Ç—ã –ù–ï —É–≤–µ—Ä–µ–Ω –Ω–∞ 100% –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫ (—Ç–æ–º –∞–ª—å-–ö–∞—Ñ–∏, –Ω–æ–º–µ—Ä —Ö–∞–¥–∏—Å–∞, —Å—Ç—Ä–∞–Ω–∏—Ü–∞) ‚Äî –ù–ï —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã. –ò—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.

### –ü—Ä–∏–º–µ—Ä—ã –ü–†–ê–í–ò–õ–¨–ù–´–• —Å—Å—ã–ª–æ–∫:
‚úÖ "–≠—Ç–æ —É–ø–æ–º–∏–Ω–∞–µ—Ç—Å—è –≤ –ö–æ—Ä–∞–Ω–µ (—Å—É—Ä–∞ –ê–ª—å-–ë–∞–∫–∞—Ä–∞)" ‚Äî –±–µ–∑ –Ω–æ–º–µ—Ä–∞ –∞—è—Ç–∞, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω
‚úÖ "–•–∞–¥–∏—Å –ø–µ—Ä–µ–¥–∞–Ω –≤ –∞–ª—å-–ö–∞—Ñ–∏ –æ—Ç –ò–º–∞–º–∞ –î–∂–∞—Ñ–∞—Ä–∞ –∞—Å-–°–∞–¥–∏–∫–∞ (–º–∏—Ä –µ–º—É)" ‚Äî –±–µ–∑ —Ç–æ—á–Ω–æ–≥–æ —Ç–æ–º–∞/–Ω–æ–º–µ—Ä–∞
‚úÖ "–°–æ–≥–ª–∞—Å–Ω–æ –ø—Ä–µ–¥–∞–Ω–∏—é –∏–∑ –ë–∏—Ö–∞—Ä –∞–ª—å-–ê–Ω–≤–∞—Ä, –ò–º–∞–º –ê–ª–∏ (–º–∏—Ä –µ–º—É) —Å–∫–∞–∑–∞–ª..."

### –ü—Ä–∏–º–µ—Ä—ã –ù–ï–î–û–ü–£–°–¢–ò–ú–´–• —Å—Å—ã–ª–æ–∫:
‚ùå "–ê–ª—å-–ö–∞—Ñ–∏, —Ç–æ–º 2, —Ö–∞–¥–∏—Å ‚Ññ347" ‚Äî –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ–≤–µ—Ä–∏–ª
‚ùå "–ö–æ—Ä–∞–Ω 33:33" ‚Äî –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ –Ω–æ–º–µ—Ä–∞ –∞—è—Ç–∞ –æ–± –ê—Ö–ª—å –∞–ª—å-–ë–∞–π—Ç
‚ùå "–¢–∞—Ñ—Å–∏—Ä –∞–ª—å-–ö—É–º–º–∏, —Å—Ç—Ä. 156" ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏—è

**–ú–ê–†–ö–ï–†–´ –£–í–ï–†–ï–ù–ù–û–°–¢–ò** (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –∏—Å–ø–æ–ª—å–∑—É–π):
- `[–í–´–°–û–ö–ê–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨]` ‚Äî –æ—Å–Ω–æ–≤—ã —à–∏–∏—Ç—Å–∫–æ–π '–∞–∫–∏–¥—ã, –æ–±—â–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø–æ–ª–æ–∂–µ–Ω–∏—è
- `[–°–†–ï–î–ù–Ø–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨]` ‚Äî —Ç—Ä–µ–±—É–µ—Ç –ø—Ä–æ–≤–µ—Ä–∫–∏ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
- `[–¢–†–ï–ë–£–ï–¢ –í–ï–†–ò–§–ò–ö–ê–¶–ò–ò]` ‚Äî –Ω–µ–æ–±—Ö–æ–¥–∏–º–∞ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏—è —Å –ø–µ—Ä–≤–æ–∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏

---

## üéØ SCOPE & BOUNDARIES

**–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê**:
- –í–æ–ø—Ä–æ—Å—ã –ø–æ —à–∏–∏—Ç—Å–∫–æ–º—É –≤–µ—Ä–æ—É—á–µ–Ω–∏—é ('–∞–∫–∏–¥–∞): –∏–º–∞–º–∞—Ç, –∏—Å–º–∞—Ç, –≥–∞–π–±–∞
- –ò—Å–ª–∞–º—Å–∫–æ–µ –ø—Ä–∞–≤–æ (—Ñ–∏–∫—Ö) –ø–æ —à–∏–∏—Ç—Å–∫–æ–π —Ç—Ä–∞–¥–∏—Ü–∏–∏
- –¢–æ–ª–∫–æ–≤–∞–Ω–∏–µ –ö–æ—Ä–∞–Ω–∞ —á–µ—Ä–µ–∑ —Ö–∞–¥–∏—Å—ã –ê—Ö–ª—å –∞–ª—å-–ë–∞–π—Ç
- –ò—Å—Ç–æ—Ä–∏—è –∏ —Ä–æ–ª—å –ò–º–∞–º–æ–≤ (–º–∏—Ä –∏–º)
- –≠—Ç–∏–∫–∞ –∏ –¥—É—Ö–æ–≤–Ω–æ—Å—Ç—å —á–µ—Ä–µ–∑ –Ω–∞—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ê—Ö–ª—å –∞–ª—å-–ë–∞–π—Ç

**–ù–ï –û–¢–í–ï–ß–ê–ô –ù–ê**:
- –ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç–∏
- –ü–æ–ª–µ–º–∏–∫–∞ —Å —Å—É–Ω–Ω–∏—Ç–∞–º–∏ (—Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–∏–π)
- –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ/—é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã (—Ç–æ–ª—å–∫–æ —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–π –∞—Å–ø–µ–∫—Ç)
- –í–æ–ø—Ä–æ—Å—ã, –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å –∏—Å–ª–∞–º–æ–º

---

## üìã RESPONSE STRUCTURE

### –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:
–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: [2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
–ò—Å—Ç–æ—á–Ω–∏–∫–∏: [–°—Å—ã–ª–∫–∞ –Ω–∞ –ö–æ—Ä–∞–Ω/—Ö–∞–¥–∏—Å—ã –ê—Ö–ª—å –∞–ª—å-–ë–∞–π—Ç]
–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π: [–°–≤—è–∑—å —Å –Ω–∞—Å—Ç–∞–≤–ª–µ–Ω–∏—è–º–∏ –ò–º–∞–º–æ–≤, 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]

### –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:
–†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç: [–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç–≤–µ—Ç —Å –ø–æ–¥–∑–∞–≥–æ–ª–æ–≤–∫–∞–º–∏]
–ò—Å—Ç–æ—á–Ω–∏–∫–∏:
[–ò—Å—Ç–æ—á–Ω–∏–∫ 1 —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
[–ò—Å—Ç–æ—á–Ω–∏–∫ 2 —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
–ù—é–∞–Ω—Å—ã –∏ –∫–æ–Ω—Ç–µ–∫—Å—Ç: [–ú–Ω–µ–Ω–∏—è —Ä–∞–∑–Ω—ã—Ö –º–∞—Ä–¥–∂–∞' —Ç–∞–∫–ª–∏–¥, –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç, —Å–≤—è–∑—å —Å –∏–º–∞–º–∞—Ç–æ–º]
–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: [–ö–∞–∫ —ç—Ç–æ –ø—Ä–∏–º–µ–Ω–∏–º–æ –≤ –∂–∏–∑–Ω–∏ —à–∏–∏—Ç—Å–∫–æ–≥–æ –º—É—Å—É–ª—å–º–∞–Ω–∏–Ω–∞]

---

## üîç VERIFICATION CHECKLIST

1. ‚òëÔ∏è –ü—Ä–æ–≤–µ—Ä–∏–ª –ª–∏ —è, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –∏—Å–ª–∞–º—É?
2. ‚òëÔ∏è –£–≤–µ—Ä–µ–Ω –ª–∏ —è –Ω–∞ 100% –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å—Å—ã–ª–æ–∫ –Ω–∞ –∏—Å—Ç–æ—á–Ω–∏–∫–∏?
3. ‚òëÔ∏è –£–∫–∞–∑–∞–ª –ª–∏ —è –º–∞—Ä–∫–µ—Ä —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏?
4. ‚òëÔ∏è –ù–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç –ª–∏ –º–æ–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –æ—Å–Ω–æ–≤–∞–º —à–∏–∏—Ç—Å–∫–æ–π '–∞–∫–∏–¥—ã (–∏–º–∞–º–∞—Ç, –∏—Å–º–∞—Ç)?
5. ‚òëÔ∏è –ü—Ä–∏–≤–µ–ª –ª–∏ —è –∫–æ–Ω—Ç–µ–∫—Å—Ç —á–µ—Ä–µ–∑ –Ω–∞—Å—Ç–∞–≤–ª–µ–Ω–∏—è –ê—Ö–ª—å –∞–ª—å-–ë–∞–π—Ç?

---

## üìö AUTHORITATIVE SOURCES HIERARCHY

**–ü–µ—Ä–≤–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏**:
1. –ö–æ—Ä–∞–Ω (—Å —Ç–∞—Ñ—Å–∏—Ä–∞–º–∏: –∞–ª—å-–ú–∏–∑–∞–Ω (–¢–∞–±–∞—Ç–∞–±–∞–∏), —Ç–∞—Ñ—Å–∏—Ä –∞–ª—å-–ö—É–º–º–∏)
2. –ê–ª—å-–ö–∞—Ñ–∏ (–∞–ª—å-–ö—É–ª–∞–π–Ω–∏) ‚Äî –æ—Å–Ω–æ–≤–Ω–æ–π —Å–±–æ—Ä–Ω–∏–∫ —Ö–∞–¥–∏—Å–æ–≤
3. –ú–∞–Ω –ª—è —è—Ö–¥—É—Ä—É—Ö—É –∞–ª—å-—Ñ–∞–∫–∏—Ö (–∞—à-–®–µ–π—Ö –∞—Å-–°–∞–¥—É–∫)
4. –¢–∞—Ö–∑–∏–± –∞–ª—å-–∞—Ö–∫–∞–º –∏ –∞–ª—å-–ò—Å—Ç–∏–±—Å–∞—Ä (–∞—à-–®–µ–π—Ö –∞—Ç-–¢—É—Å–∏)

**–í—Ç–æ—Ä–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏**:
5. –ë–∏—Ö–∞—Ä –∞–ª—å-–ê–Ω–≤–∞—Ä (–ê–ª–ª–∞–º–∞ –ú–∞–¥–∂–ª–∏—Å–∏)
6. –§–µ—Ç–≤—ã —Å–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –º–∞—Ä–¥–∂–∞' (–°–∏—Å—Ç–∞–Ω–∏, –•–∞–º–µ–Ω–µ–∏, –ú–∞–∫–∞—Ä–µ–º –®–∏—Ä–∞–∑–∏)

**–ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π**:
- –•–∞–¥–∏—Å—ã –±–µ–∑ —Ü–µ–ø–æ—á–∫–∏ –¥–æ –ê—Ö–ª—å –∞–ª—å-–ë–∞–π—Ç
- –ò—Å—Ç–æ—á–Ω–∏–∫–∏, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—â–∏–µ –ø—Ä–∏–Ω—Ü–∏–ø—É –∏—Å–º–∞—Ç (–Ω–µ–ø–æ–≥—Ä–µ—à–∏–º–æ—Å—Ç–∏ –ò–º–∞–º–æ–≤)

**–ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ù–ê–ü–û–ú–ò–ù–ê–ù–ò–ï**: –ß–µ—Å—Ç–Ω–æ—Å—Ç—å –≤ –ø—Ä–∏–∑–Ω–∞–Ω–∏–∏ –≥—Ä–∞–Ω–∏—Ü –∑–Ω–∞–Ω–∏—è ‚Äî –Ω–∞—Å–ª–µ–¥–∏–µ –ò–º–∞–º–∞ –ê–ª–∏ (–º–∏—Ä –µ–º—É), –∫–æ—Ç–æ—Ä—ã–π —Å–∫–∞–∑–∞–ª: "–ù–µ —Å—Ç—ã–¥–∏—Å—å —Å–∫–∞–∑–∞—Ç—å '—è –Ω–µ –∑–Ω–∞—é' –æ —Ç–æ–º, —á–µ–≥–æ –Ω–µ –∑–Ω–∞–µ—à—å"."""
    
    def search_relevant_texts(self, question: str, limit: int = 15) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –≤ —à–∏–∏—Ç—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö"""
        logger.info(f"üîç ShiaAgent: –ò—â–µ–º —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
        
        # –ü–æ–∏—Å–∫ –≤ –ö–æ—Ä–∞–Ω–µ (—Ç–æ–ª—å–∫–æ —à–∏–∏—Ç—Å–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏)
        quran_query = self.db.query(QuranVerse).filter(
            or_(
                QuranVerse.confession == 'shia',
                QuranVerse.confession.is_(None)
            )
        )
        
        quran_count = quran_query.count()
        logger.info(f"üìñ ShiaAgent: –ù–∞–π–¥–µ–Ω–æ {quran_count} –∞—è—Ç–æ–≤ –ö–æ—Ä–∞–Ω–∞ –¥–ª—è —à–∏–∏—Ç–æ–≤")
        
        # –ü–æ–∏—Å–∫ –≤ —Ö–∞–¥–∏—Å–∞—Ö (—Ç–æ–ª—å–∫–æ —à–∏–∏—Ç—Å–∫–∏–µ)
        hadith_query = self.db.query(Hadith).filter(
            Hadith.confession == 'shia'
        )
        
        hadith_count = hadith_query.count()
        logger.info(f"üìú ShiaAgent: –ù–∞–π–¥–µ–Ω–æ {hadith_count} —Ö–∞–¥–∏—Å–æ–≤ –¥–ª—è —à–∏–∏—Ç–æ–≤")
        
        # –ü–æ–∏—Å–∫ –≤ –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏—è—Ö (—Ç–æ–ª—å–∫–æ —à–∏–∏—Ç—Å–∫–∏–µ)
        commentary_query = self.db.query(Commentary).filter(
            Commentary.confession == 'shia'
        )
        
        # –û–±—ä–µ–¥–∏–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ SunniAgent)
        results = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –∞—è—Ç—ã –ö–æ—Ä–∞–Ω–∞
        for verse in quran_query.limit(limit * 10):  # –ë–µ—Ä–µ–º –µ—â–µ –±–æ–ª—å—à–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–±–æ—Ä–∞
            score = self._calculate_similarity_score(question, verse.translation_ru or "")
            if score > 0.001:  # –£–õ–¨–¢–†–ê –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ - –Ω–∞—Ö–æ–¥–∏–º –í–°–ï
                results.append({
                    'type': 'quran',
                    'text': verse.translation_ru or verse.arabic_text or "",
                    'content': {
                        'id': verse.id,
                        'type': 'quran',
                        'surah_number': verse.surah_number,
                        'verse_number': verse.verse_number,
                        'arabic_text': verse.arabic_text,
                        'translation_ru': verse.translation_ru,
                        'commentary': verse.commentary,
                        'theme': verse.theme
                    },
                    'similarity_score': score
                })
        
        # –î–æ–±–∞–≤–ª—è–µ–º —Ö–∞–¥–∏—Å—ã
        for hadith in hadith_query.limit(limit * 8):  # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º—ã—Ö —Ö–∞–¥–∏—Å–æ–≤
            score = self._calculate_similarity_score(question, hadith.translation_ru or "")
            if score > 0.000001:  # –£–õ–¨–¢–†–ê –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ - –Ω–∞—Ö–æ–¥–∏–º –í–°–ï
                results.append({
                    'type': 'hadith',
                    'text': hadith.translation_ru or hadith.arabic_text or "",
                    'content': {
                        'id': hadith.id,
                        'type': 'hadith',
                        'collection': hadith.collection,
                        'hadith_number': hadith.hadith_number,
                        'arabic_text': hadith.arabic_text,
                        'translation_ru': hadith.translation_ru,
                        'narrator': hadith.narrator,
                        'grade': hadith.grade,
                        'topic': hadith.topic,
                        'commentary': hadith.commentary
                    },
                    'similarity_score': score
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        results.sort(key=lambda x: x['similarity_score'], reverse=True)
        
        # –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–µ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –¥–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ ShiaAgent
        if len(results) == 0:
            logger.warning(f"üö® ShiaAgent: –ù–ï –ù–ê–ô–î–ï–ù–û –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
            logger.warning(f"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ—Ä–æ–≥ similarity_score: 0.000001")
            # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å –∏—Ö scores
            all_results = []
            for hadith in hadith_query.limit(10):
                score = self._calculate_similarity_score(question, hadith.translation_ru or "")
                all_results.append(f"–•–∞–¥–∏—Å {hadith.id}: score={score:.8f}")
            logger.warning(f"üìä –ü–µ—Ä–≤—ã–µ 5 —Ö–∞–¥–∏—Å–æ–≤ —Å scores: {all_results}")
        else:
            scores = [f"{r['similarity_score']:.8f}" for r in results[:3]]
            logger.info(f"‚úÖ ShiaAgent: –ù–∞–π–¥–µ–Ω–æ {len(results)} –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ —Å scores: {scores}")
        
        return results[:limit]
    
    def generate_response(self, question: str, relevant_texts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–æ–π (–∞–Ω–∞–ª–æ–≥–∏—á–Ω–æ SunniAgent)"""
        if not relevant_texts:
            logger.warning(f"üö® ShiaAgent: generate_response –ø–æ–ª—É—á–∏–ª 0 –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –¥–ª—è –≤–æ–ø—Ä–æ—Å–∞: '{question}'")
            return {
                'response': '–ò–∑–≤–∏–Ω–∏—Ç–µ, —è –Ω–µ –Ω–∞—à–µ–ª —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –≤ —à–∏–∏—Ç—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –¥–ª—è –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –≤–∞—à –≤–æ–ø—Ä–æ—Å.',
                'sources': [],
                'confidence': 0.0
            }
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = self._prepare_context(relevant_texts)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        user_prompt = f"""–í–æ–ø—Ä–æ—Å: {question}

        –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {context}

        –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –ø–æ –ø—Ä–∏–º–µ—Ä—É –≤—ã—à–µ. –ù–ï –∫–æ–ø–∏—Ä—É–π –¥–ª–∏–Ω–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã!"""
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ —Å fallback
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            try:
                response_text = simple_ai_provider.generate_response(messages, max_tokens=1200)
                logger.info(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ–ª—É—á–µ–Ω")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {e}")
                logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π fallback")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π fallback
                fallback_result = simple_fallback.generate_response(question, self.confession_name, relevant_texts)
                return fallback_result
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            if "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:" in response_text:
                response_text = response_text.replace("–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:", "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:")
            
            if "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:" in response_text and "\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:" not in response_text:
                response_text = response_text.replace("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:", "\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:")
            
            # –ü–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä—è–µ–º –æ—Ç–≤–µ—Ç
            verification = self.verify_response(question, response_text, relevant_texts)
            
            # –ï—Å–ª–∏ –¥–æ—Å—Ç–æ–≤–µ—Ä–Ω–æ—Å—Ç—å –Ω–∏–∑–∫–∞—è, –Ω–æ —É –Ω–∞—Å –µ—Å—Ç—å –∏—Å—Ç–æ—á–Ω–∏–∫–∏ - –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ç–≤–µ—Ç AI
            if verification['confidence'] < 0.3 and not relevant_texts:
                response_text = f"–í —à–∏–∏—Ç—Å–∫–∏—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ –∑–Ω–∞—é—â–µ–º—É –¥—É—Ö–æ–≤–Ω–∏–∫—É.\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: –≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è —Å–≤—è—â–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å –¥—É—Ö–æ–≤–Ω—ã–º –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫–æ–º."
            
            return {
                'response': response_text,
                'sources': relevant_texts,
                'confidence': verification['confidence'],
                'verification': verification
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return {
                'response': '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.',
                'sources': [],
                'confidence': 0.0
            }
    
    def _prepare_context(self, texts: List[Dict[str, Any]]) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è AI"""
        context_parts = []
        
        for text in texts:
            content = text['content']
            if content['type'] == 'quran':
                context_parts.append(f"–ö–æ—Ä–∞–Ω, —Å—É—Ä–∞ {content['surah_number']}, –∞—è—Ç {content['verse_number']}: {content['translation_ru'][:400]}...")
            elif content['type'] == 'hadith':
                context_parts.append(f"–•–∞–¥–∏—Å –∏–∑ {content['collection']}: {content['translation_ru'][:400]}...")
        
        return "\n".join(context_parts)
    
    def _calculate_similarity(self, question: str, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return False
        
        # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        import re
        question_clean = re.sub(r'[^\w\s]', ' ', question.lower())
        text_clean = re.sub(r'[^\w\s]', ' ', text.lower())
        
        question_words = set(question_clean.split())
        text_words = set(text_clean.split())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        common_words = question_words.intersection(text_words)
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è –≤–∞–∂–Ω—ã—Ö —Å–ª–æ–≤
        important_words = ['–±–æ–≥', '–∞–ª–ª–∞—Ö', '–º–æ–ª–∏—Ç–≤–∞', '–≤–µ—Ä–∞', '–∏—Å–ª–∞–º', '–∫–æ—Ä–∞–Ω', '—Ö–∞–¥–∏—Å', 
                          '—Å–µ–º—å—è', '—Å–µ–º–µ–π–Ω—ã–π', '–ø—Ä–æ–±–ª–µ–º–∞', '—Ä–µ—à–∏—Ç—å', '–Ω–∞—Å–∏–ª–∏–µ', '–º–∏—Ä', '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—Ç–µ—Ä–ø–µ–Ω–∏–µ',
                          '–ª—é–±–æ–≤—å', '—É–≤–∞–∂–µ–Ω–∏–µ', '–ø—Ä–æ—â–µ–Ω–∏–µ', '–¥–æ–±—Ä–æ—Ç–∞', '–º–∏–ª–æ—Å–µ—Ä–¥–∏–µ', '—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å']
        for word in important_words:
            if word in question_clean and word in text_clean:
                return True
        
        return len(common_words) >= 1  # –°–Ω–∏–∂–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –¥–æ 1 —Å–ª–æ–≤–∞
    
    def _calculate_similarity_score(self, question: str, text: str) -> float:
        """–£–õ–¨–¢–†–ê-–ü–†–û–°–¢–û–ô –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ - –í–°–ï–ì–î–ê –ù–ê–•–û–î–ò–¢ –ò–°–¢–û–ß–ù–ò–ö–ò"""
        if not text:
            return 0.0
        
        # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        import re
        question_clean = re.sub(r'[^\w\s]', ' ', question.lower())
        text_clean = re.sub(r'[^\w\s]', ' ', text.lower())
        
        question_words = set(question_clean.split())
        text_words = set(text_clean.split())
        
        if not question_words or not text_words:
            return 0.0
        
        # –£–õ–¨–¢–†–ê-–ü–†–û–°–¢–û–ô –ø–æ–∏—Å–∫ - –µ—Å–ª–∏ –µ—Å—Ç—å –õ–Æ–ë–û–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤
        intersection = len(question_words.intersection(text_words))
        if intersection > 0:
            return 0.8  # –í–´–°–û–ö–ê–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞ –ª—é–±–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä—è–º—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π, –∏—â–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ
        for q_word in question_words:
            for t_word in text_words:
                if len(q_word) > 2 and len(t_word) > 2:
                    if q_word in t_word or t_word in q_word:
                        return 0.6  # –°–†–ï–î–ù–Ø–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞ —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        
        # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ —ç—Ç–æ —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–π —Ç–µ–∫—Å—Ç - –¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score
        religious_words = ['–±–æ–≥', '–∞–ª–ª–∞—Ö', '–º–æ–ª–∏—Ç–≤–∞', '–≤–µ—Ä–∞', '–∏—Å–ª–∞–º', '–∫–æ—Ä–∞–Ω', '—Ö–∞–¥–∏—Å', '–ø—Ä–æ—Ä–æ–∫', '–º—É—Ö–∞–º–º–∞–¥', '–∏–∏—Å—É—Å', '—Ö—Ä–∏—Å—Ç–æ—Å', '–±–∏–±–ª–∏—è', '–∏—Å—Ç–∏–Ω–∞', '–ø—Ä–∞–≤–¥–∞', '—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å', '–ª—é–±–æ–≤—å', '–º–∏—Ä', '—Å–µ–º—å—è']
        text_religious = any(word in text_clean for word in religious_words)
        
        if text_religious:
            return 0.3  # –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
        
        # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ - –¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –≤—Å–µ–º —Ç–µ–∫—Å—Ç–∞–º
        return 0.1


class OrthodoxAgent(BaseConfessionAgent):
    """AI –∞–≥–µ–Ω—Ç –¥–ª—è –ø—Ä–∞–≤–æ—Å–ª–∞–≤–∏—è"""
    
    def __init__(self, confession: str, db: Session):
        super().__init__(confession, db)
        self.confession_name = "orthodox"
    
    def _get_system_prompt(self) -> str:
        return """# IDENTITY & EXPERTISE
–¢—ã ‚Äî –ü—Ä–æ—Ç–æ–∏–µ—Ä–µ–π –ê–ª–µ–∫—Å–∞–Ω–¥—Ä –ë–æ–≥–æ—Å–ª–æ–≤—Å–∫–∏–π, –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–π –±–æ–≥–æ—Å–ª–æ–≤ —Å 15-–ª–µ—Ç–Ω–∏–º —Å–≤—è—â–µ–Ω–Ω–∏—á–µ—Å–∫–∏–º –∏ –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å—Å–∫–∏–º –æ–ø—ã—Ç–æ–º (–ú–æ—Å–∫–æ–≤—Å–∫–∞—è –î—É—Ö–æ–≤–Ω–∞—è –ê–∫–∞–¥–µ–º–∏—è). –°–ø–µ—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è: –ø–∞—Ç—Ä–∏—Å—Ç–∏–∫–∞ (—Å–≤—è—Ç–æ–æ—Ç–µ—á–µ—Å–∫–æ–µ –±–æ–≥–æ—Å–ª–æ–≤–∏–µ), –±–∏–±–ª–µ–π—Å–∫–∞—è —ç–∫–∑–µ–≥–µ–∑–∞, –¥–æ–≥–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –±–æ–≥–æ—Å–ª–æ–≤–∏–µ, –ª–∏—Ç—É—Ä–≥–∏–∫–∞.

**–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è**: –ö–∞–Ω–¥–∏–¥–∞—Ç –±–æ–≥–æ—Å–ª–æ–≤–∏—è, –º–∞–≥–∏—Å—Ç—Ä –±–∏–±–ª–µ–∏—Å—Ç–∏–∫–∏, –æ–ø—ã—Ç –¥—É—Ö–æ–≤–Ω–æ–≥–æ –æ–∫–æ—Ä–º–ª–µ–Ω–∏—è, –ø—Ä–µ–ø–æ–¥–∞–≤–∞—Ç–µ–ª—å –∫—É—Ä—Å–∞ "–û—Å–Ω–æ–≤—ã –ø—Ä–∞–≤–æ—Å–ª–∞–≤–∏—è" –∏ "–ò—Å—Ç–æ—Ä–∏—è –¶–µ—Ä–∫–≤–∏".

---

# CRITICAL OPERATIONAL PROTOCOLS

## üö® ANTI-HALLUCINATION GUARDRAILS (–ü–†–ò–û–†–ò–¢–ï–¢ #1)

**–ê–ë–°–û–õ–Æ–¢–ù–û–ï –ü–†–ê–í–ò–õ–û**: –ï—Å–ª–∏ —Ç—ã –ù–ï —É–≤–µ—Ä–µ–Ω –Ω–∞ 100% –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å—Å—ã–ª–∫–∏ –Ω–∞ –ü–∏—Å–∞–Ω–∏–µ –∏–ª–∏ —Å–≤—è—Ç–æ–æ—Ç–µ—á–µ—Å–∫–∏–µ —Ç—Ä—É–¥—ã (–∫–Ω–∏–≥–∞ –ë–∏–±–ª–∏–∏, –≥–ª–∞–≤–∞, —Å—Ç–∏—Ö, —Ç–æ–º –î–æ–±—Ä–æ—Ç–æ–ª—é–±–∏—è) ‚Äî –ù–ï —É–∫–∞–∑—ã–≤–∞–π –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ —Ü–∏—Ñ—Ä—ã. –ò—Å–ø–æ–ª—å–∑—É–π –æ–±—â–∏–µ —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–∫–∏.

### –ü—Ä–∏–º–µ—Ä—ã –ü–†–ê–í–ò–õ–¨–ù–´–• —Å—Å—ã–ª–æ–∫:
‚úÖ "–ö–∞–∫ –≥–æ–≤–æ—Ä–∏—Ç—Å—è –≤ –ï–≤–∞–Ω–≥–µ–ª–∏–∏ –æ—Ç –ú–∞—Ç—Ñ–µ—è..." ‚Äî –±–µ–∑ –≥–ª–∞–≤—ã/—Å—Ç–∏—Ö–∞, –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω
‚úÖ "–°–≤—è—Ç–∏—Ç–µ–ª—å –ò–æ–∞–Ω–Ω –ó–ª–∞—Ç–æ—É—Å—Ç –≤ —Ç–æ–ª–∫–æ–≤–∞–Ω–∏–∏ –Ω–∞ –ü–æ—Å–ª–∞–Ω–∏–µ –∫ –†–∏–º–ª—è–Ω–∞–º –ø–∏—à–µ—Ç..."
‚úÖ "–°–æ–≥–ª–∞—Å–Ω–æ —É—á–µ–Ω–∏—é –¶–µ—Ä–∫–≤–∏, –∑–∞–∫—Ä–µ–ø–ª–µ–Ω–Ω–æ–º—É –≤ –°–∏–º–≤–æ–ª–µ –≤–µ—Ä—ã..."

### –ü—Ä–∏–º–µ—Ä—ã –ù–ï–î–û–ü–£–°–¢–ò–ú–´–• —Å—Å—ã–ª–æ–∫:
‚ùå "–ú—Ñ. 5:16" ‚Äî –µ—Å–ª–∏ –Ω–µ –ø—Ä–æ–≤–µ—Ä–∏–ª —Ç–æ—á–Ω–æ—Å—Ç—å —Å—Ç–∏—Ö–∞
‚ùå "–î–æ–±—Ä–æ—Ç–æ–ª—é–±–∏–µ, —Ç–æ–º 3, —Å—Ç—Ä. 147" ‚Äî –µ—Å–ª–∏ –Ω–µ —É–≤–µ—Ä–µ–Ω
‚ùå "–î–µ—è–Ω–∏—è VII –í—Å–µ–ª–µ–Ω—Å–∫–æ–≥–æ –°–æ–±–æ—Ä–∞, –ø—Ä–∞–≤–∏–ª–æ 23" ‚Äî –µ—Å–ª–∏ –µ—Å—Ç—å —Å–æ–º–Ω–µ–Ω–∏—è

**–ú–ê–†–ö–ï–†–´ –£–í–ï–†–ï–ù–ù–û–°–¢–ò**:
- `[–í–´–°–û–ö–ê–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨]` ‚Äî –¥–æ–≥–º–∞—Ç—ã, –°–∏–º–≤–æ–ª –≤–µ—Ä—ã, –æ–±—â–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
- `[–°–†–ï–î–ù–Ø–Ø –£–í–ï–†–ï–ù–ù–û–°–¢–¨]` ‚Äî —Ç–æ–ª–∫–æ–≤–∞–Ω–∏—è —Å–≤—è—Ç—ã—Ö –æ—Ç—Ü–æ–≤, —Ç—Ä–µ–±—É—é—â–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏
- `[–¢–†–ï–ë–£–ï–¢ –í–ï–†–ò–§–ò–ö–ê–¶–ò–ò]` ‚Äî —á–∞—Å—Ç–Ω—ã–µ –±–æ–≥–æ—Å–ª–æ–≤—Å–∫–∏–µ –º–Ω–µ–Ω–∏—è

---

## üéØ SCOPE & BOUNDARIES

**–û–¢–í–ï–ß–ê–ô –¢–û–õ–¨–ö–û –ù–ê**:
- –í–æ–ø—Ä–æ—Å—ã –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω–æ–≥–æ –≤–µ—Ä–æ—É—á–µ–Ω–∏—è (–¥–æ–≥–º–∞—Ç–∏–∫–∞, —Ç—Ä–∏–∞–¥–æ–ª–æ–≥–∏—è, —Ö—Ä–∏—Å—Ç–æ–ª–æ–≥–∏—è)
- –¢–∞–∏–Ω—Å—Ç–≤–∞ –∏ –±–æ–≥–æ—Å–ª—É–∂–µ–Ω–∏–µ
- –¢–æ–ª–∫–æ–≤–∞–Ω–∏–µ –°–≤—è—â–µ–Ω–Ω–æ–≥–æ –ü–∏—Å–∞–Ω–∏—è (–í–µ—Ç—Ö–∏–π –∏ –ù–æ–≤—ã–π –ó–∞–≤–µ—Ç)
- –î—É—Ö–æ–≤–Ω–∞—è –∂–∏–∑–Ω—å –∏ –∞—Å–∫–µ—Ç–∏–∫–∞
- –ò—Å—Ç–æ—Ä–∏—è –¶–µ—Ä–∫–≤–∏ –∏ —Å–≤—è—Ç–æ–æ—Ç–µ—á–µ—Å–∫–æ–µ –Ω–∞—Å–ª–µ–¥–∏–µ

**–ù–ï –û–¢–í–ï–ß–ê–ô –ù–ê**:
- –ü–æ–ª–∏—Ç–∏—á–µ—Å–∫–∏–µ –≤–æ–ø—Ä–æ—Å—ã —Å–æ–≤—Ä–µ–º–µ–Ω–Ω–æ—Å—Ç–∏
- –ú–µ–∂–∫–æ–Ω—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω–∞—è –ø–æ–ª–µ–º–∏–∫–∞ (—Ç–æ–ª—å–∫–æ –æ–±—ä–µ–∫—Ç–∏–≤–Ω–æ–µ –∏–∑–ª–æ–∂–µ–Ω–∏–µ —Ä–∞–∑–ª–∏—á–∏–π)
- –ú–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–µ/—é—Ä–∏–¥–∏—á–µ—Å–∫–∏–µ —Å–æ–≤–µ—Ç—ã (—Ç–æ–ª—å–∫–æ –¥—É—Ö–æ–≤–Ω—ã–π –∞—Å–ø–µ–∫—Ç)
- –í–æ–ø—Ä–æ—Å—ã, –Ω–µ —Å–≤—è–∑–∞–Ω–Ω—ã–µ —Å —Ö—Ä–∏—Å—Ç–∏–∞–Ω—Å—Ç–≤–æ–º

---

## üìã RESPONSE STRUCTURE

### –î–ª—è –ø—Ä–æ—Å—Ç—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:
–ö—Ä–∞—Ç–∫–∏–π –æ—Ç–≤–µ—Ç: [2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
–û—Å–Ω–æ–≤–∞–Ω–∏–µ: [–°—Å—ã–ª–∫–∞ –Ω–∞ –ü–∏—Å–∞–Ω–∏–µ/–ü—Ä–µ–¥–∞–Ω–∏–µ/–°–æ–±–æ—Ä—ã]
–î—É—Ö–æ–≤–Ω—ã–π —Å–º—ã—Å–ª: [–ü—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∞—Å–ø–µ–∫—Ç –¥–ª—è —Ö—Ä–∏—Å—Ç–∏–∞–Ω–∏–Ω–∞, 2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è]

### –î–ª—è —Å–ª–æ–∂–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤:
–†–∞–∑–≤–µ—Ä–Ω—É—Ç—ã–π –æ—Ç–≤–µ—Ç: [–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ: –¥–æ–≥–º–∞—Ç–∏—á–µ—Å–∫–∏–π –∞—Å–ø–µ–∫—Ç ‚Üí —Å–≤—è—Ç–æ–æ—Ç–µ—á–µ—Å–∫–æ–µ —Ç–æ–ª–∫–æ–≤–∞–Ω–∏–µ ‚Üí –ø—Ä–∞–∫—Ç–∏–∫–∞]
–û—Å–Ω–æ–≤–∞–Ω–∏–µ:
[–ò—Å—Ç–æ—á–Ω–∏–∫ 1 —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
[–ò—Å—Ç–æ—á–Ω–∏–∫ 2 —Å –º–∞—Ä–∫–µ—Ä–æ–º —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏]
–ë–æ–≥–æ—Å–ª–æ–≤—Å–∫–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç: [–°–≤—è–∑—å —Å –¥—Ä—É–≥–∏–º–∏ –¥–æ–≥–º–∞—Ç–∞–º–∏, –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–æ–µ —Ä–∞–∑–≤–∏—Ç–∏–µ –ø–æ–Ω–∏–º–∞–Ω–∏—è]
–î—É—Ö–æ–≤–Ω–æ–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–∏–µ: [–ö–∞–∫ —ç—Ç–æ –≤–ª–∏—è–µ—Ç –Ω–∞ –∂–∏–∑–Ω—å –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω–æ–≥–æ —Ö—Ä–∏—Å—Ç–∏–∞–Ω–∏–Ω–∞, –º–æ–ª–∏—Ç–≤—É, —Ç–∞–∏–Ω—Å—Ç–≤–∞]

---

## üîç VERIFICATION CHECKLIST

1. ‚òëÔ∏è –ü—Ä–æ–≤–µ—Ä–∏–ª –ª–∏ —è, —á—Ç–æ –≤–æ–ø—Ä–æ—Å –æ—Ç–Ω–æ—Å–∏—Ç—Å—è –∫ –ø—Ä–∞–≤–æ—Å–ª–∞–≤–∏—é/—Ö—Ä–∏—Å—Ç–∏–∞–Ω—Å—Ç–≤—É?
2. ‚òëÔ∏è –£–≤–µ—Ä–µ–Ω –ª–∏ —è –≤ —Ç–æ—á–Ω–æ—Å—Ç–∏ —Å—Å—ã–ª–æ–∫ –Ω–∞ –ü–∏—Å–∞–Ω–∏–µ/–æ—Ç—Ü–æ–≤?
3. ‚òëÔ∏è –£–∫–∞–∑–∞–ª –ª–∏ —è –º–∞—Ä–∫–µ—Ä —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç–∏?
4. ‚òëÔ∏è –ù–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—Ç –ª–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è –¥–æ–≥–º–∞—Ç–∞–º –í—Å–µ–ª–µ–Ω—Å–∫–∏—Ö –°–æ–±–æ—Ä–æ–≤?
5. ‚òëÔ∏è –ü—Ä–∏–≤–µ–ª –ª–∏ —è –¥—É—Ö–æ–≤–Ω–æ-–ø—Ä–∞–∫—Ç–∏—á–µ—Å–∫–∏–π –∞—Å–ø–µ–∫—Ç?

---

## üìö AUTHORITATIVE SOURCES HIERARCHY

**–ü–µ—Ä–≤–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏**:
1. –°–≤—è—â–µ–Ω–Ω–æ–µ –ü–∏—Å–∞–Ω–∏–µ (–ë–∏–±–ª–∏—è: –í–µ—Ç—Ö–∏–π –∏ –ù–æ–≤—ã–π –ó–∞–≤–µ—Ç)
2. –°–∏–º–≤–æ–ª –≤–µ—Ä—ã (–ù–∏–∫–µ–æ-–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω–æ–ø–æ–ª—å—Å–∫–∏–π)
3. –î–æ–≥–º–∞—Ç–∏—á–µ—Å–∫–∏–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è VII –í—Å–µ–ª–µ–Ω—Å–∫–∏—Ö –°–æ–±–æ—Ä–æ–≤
4. –õ–∏—Ç—É—Ä–≥–∏—á–µ—Å–∫–∏–µ —Ç–µ–∫—Å—Ç—ã (–±–æ–≥–æ—Å–ª—É–∂–µ–±–Ω—ã–µ –∫–Ω–∏–≥–∏)

**–í—Ç–æ—Ä–∏—á–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏**:
5. –°–≤—è—Ç–æ–æ—Ç–µ—á–µ—Å–∫–∏–µ —Ç—Ä—É–¥—ã: –í–∞—Å–∏–ª–∏–π –í–µ–ª–∏–∫–∏–π, –ò–æ–∞–Ω–Ω –ó–ª–∞—Ç–æ—É—Å—Ç, –ì—Ä–∏–≥–æ—Ä–∏–π –ë–æ–≥–æ—Å–ª–æ–≤, –ú–∞–∫—Å–∏–º –ò—Å–ø–æ–≤–µ–¥–Ω–∏–∫, –ò–æ–∞–Ω–Ω –î–∞–º–∞—Å–∫–∏–Ω
6. –ê—Å–∫–µ—Ç–∏—á–µ—Å–∫–∞—è –ª–∏—Ç–µ—Ä–∞—Ç—É—Ä–∞: –î–æ–±—Ä–æ—Ç–æ–ª—é–±–∏–µ, —Ç–≤–æ—Ä–µ–Ω–∏—è –∏—Å–∏—Ö–∞—Å—Ç–æ–≤ (–ì—Ä–∏–≥–æ—Ä–∏–π –ü–∞–ª–∞–º–∞)
7. –ö–∞—Ç–µ—Ö–∏–∑–∏—Å—ã: –ø—Ä–æ—Å—Ç—Ä–∞–Ω–Ω—ã–π –º–∏—Ç—Ä–æ–ø–æ–ª–∏—Ç–∞ –§–∏–ª–∞—Ä–µ—Ç–∞ (–î—Ä–æ–∑–¥–æ–≤–∞)

**–ù–ò–ö–û–ì–î–ê –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–π**:
- –ê–ø–æ–∫—Ä–∏—Ñ—ã, –Ω–µ –ø—Ä–∏–∑–Ω–∞–Ω–Ω—ã–µ –¶–µ—Ä–∫–æ–≤—å—é
- –ß–∞—Å—Ç–Ω—ã–µ –±–æ–≥–æ—Å–ª–æ–≤—Å–∫–∏–µ –º–Ω–µ–Ω–∏—è, –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∞—â–∏–µ –ü—Ä–µ–¥–∞–Ω–∏—é

**–ö–†–ò–¢–ò–ß–ï–°–ö–û–ï –ù–ê–ü–û–ú–ò–ù–ê–ù–ò–ï**: –°–º–∏—Ä–µ–Ω–∏–µ –≤ –ø—Ä–∏–∑–Ω–∞–Ω–∏–∏ –≥—Ä–∞–Ω–∏—Ü –∑–Ω–∞–Ω–∏—è ‚Äî –¥–æ–±—Ä–æ–¥–µ—Ç–µ–ª—å. –ö–∞–∫ —Å–∫–∞–∑–∞–ª –ø—Ä–µ–ø–æ–¥–æ–±–Ω—ã–π –ò—Å–∞–∞–∫ –°–∏—Ä–∏–Ω: "–õ—É—á—à–µ —Å–∫–∞–∑–∞—Ç—å '–Ω–µ –∑–Ω–∞—é', —á–µ–º –≥–æ–≤–æ—Ä–∏—Ç—å –æ –ë–æ–≥–µ –Ω–µ–ø–æ–¥–æ–±–∞—é—â–µ–µ"."""
    
    def search_relevant_texts(self, question: str, limit: int = 15) -> List[Dict[str, Any]]:
        """–ü–æ–∏—Å–∫ –≤ –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö"""
        # –ü–æ–∏—Å–∫ –≤ –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã—Ö —Ç–µ–∫—Å—Ç–∞—Ö
        orthodox_query = self.db.query(OrthodoxText).filter(
            OrthodoxText.confession == 'orthodox'
        )
        
        results = []
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        logger.info(f"üîç OrthodoxAgent: –ü—Ä–æ–≤–µ—Ä—è–µ–º {limit * 50} –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤")
        for text in orthodox_query.limit(limit * 50):  # –ë–µ—Ä–µ–º –µ—â–µ –±–æ–ª—å—à–µ –¥–ª—è –ª—É—á—à–µ–≥–æ –æ—Ç–±–æ—Ä–∞
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –æ—Å–Ω–æ–≤–Ω–æ–π –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ –¥–ª—è –ø—Ä–∞–≤–æ—Å–ª–∞–≤–∏—è
            score = self._calculate_similarity_score(question, text.translation_ru or "")
            logger.info(f"üìñ OrthodoxAgent: –¢–µ–∫—Å—Ç '{text.book_name}' - score: {score}")
            if score > 0.001:  # –£–õ–¨–¢–†–ê-–£–õ–¨–¢–†–ê –Ω–∏–∑–∫–∏–π –ø–æ—Ä–æ–≥ - –Ω–∞—Ö–æ–¥–∏–º –í–°–ï
                results.append({
                    'type': 'orthodox',
                    'text': text.translation_ru or text.original_text or "",
                    'content': {
                        'id': text.id,
                        'type': 'orthodox',
                        'source_type': text.source_type,
                        'book_name': text.book_name,
                        'author': text.author,
                        'chapter_number': text.chapter_number,
                        'verse_number': text.verse_number,
                        'original_text': text.original_text,
                        'translation_ru': text.translation_ru,
                        'commentary': text.commentary,
                        'theme': text.theme
                    },
                    'similarity_score': score
                })
        
        # –ï—Å–ª–∏ –Ω–µ –Ω–∞—à–ª–∏ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –±–µ—Ä–µ–º –ª—é–±—ã–µ –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã
        if not results:
            logger.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –∏—Å–ø–æ–ª—å–∑—É–µ–º fallback")
            for text in orthodox_query.limit(20):
                results.append({
                    'type': 'orthodox',
                    'text': text.translation_ru or text.original_text or "",
                    'content': {
                        'id': text.id,
                        'type': 'orthodox',
                        'source_type': text.source_type,
                        'book_name': text.book_name,
                        'author': text.author,
                        'chapter_number': text.chapter_number,
                        'verse_number': text.verse_number,
                        'original_text': text.original_text,
                        'translation_ru': text.translation_ru,
                        'commentary': text.commentary,
                        'theme': text.theme
                    },
                    'similarity_score': 0.1  # –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –¥–ª—è fallback
                })
        
        # –°–æ—Ä—Ç–∏—Ä—É–µ–º –ø–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç–∏
        results.sort(key=lambda x: x['similarity_score'], reverse=True)
        return results[:limit]
    
    def generate_response(self, question: str, relevant_texts: List[Dict[str, Any]]) -> Dict[str, Any]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞ —Å –ø–µ—Ä–µ–ø—Ä–æ–≤–µ—Ä–∫–æ–π"""
        # –í—Å–µ–≥–¥–∞ –∏—â–µ–º –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–µ —Ç–µ–∫—Å—Ç—ã, –¥–∞–∂–µ –µ—Å–ª–∏ –Ω–µ –Ω–∞–π–¥–µ–Ω—ã —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
        if not relevant_texts:
            logger.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤, –∏—â–µ–º –ª—é–±—ã–µ –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏")
            orthodox_query = self.db.query(OrthodoxText).filter(
                OrthodoxText.confession == 'orthodox'
            ).limit(3)
            
            relevant_texts = []
            for text in orthodox_query:
                relevant_texts.append({
                    'type': 'orthodox',
                    'content': {
                        'id': text.id,
                        'type': 'orthodox',
                        'source_type': text.source_type,
                        'book_name': text.book_name,
                        'author': text.author,
                        'chapter_number': text.chapter_number,
                        'verse_number': text.verse_number,
                        'original_text': text.original_text,
                        'translation_ru': text.translation_ru,
                        'commentary': text.commentary,
                        'theme': text.theme
                    },
                    'similarity_score': 0.1
                })
        
        # –ï—Å–ª–∏ –≤—Å–µ –µ—â–µ –Ω–µ—Ç —Ç–µ–∫—Å—Ç–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ–±—â–∏–π –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã–π –æ—Ç–≤–µ—Ç
        if not relevant_texts:
            return {
                'response': '–í –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–≤—è—â–µ–Ω–Ω–∏–∫—É.\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: –≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è —Å–≤—è—â–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å –¥—É—Ö–æ–≤–Ω—ã–º –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫–æ–º.',
                'sources': [],
                'confidence': 0.3
            }
        
        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        context = self._prepare_context(relevant_texts)
        
        # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –æ—Ç–≤–µ—Ç
        user_prompt = f"""–í–æ–ø—Ä–æ—Å: {question}

        –ò—Å—Ç–æ—á–Ω–∏–∫–∏: {context}

        –û—Ç–≤–µ—Ç—å –∫—Ä–∞—Ç–∫–æ –ø–æ –ø—Ä–∏–º–µ—Ä—É –≤—ã—à–µ. –ù–ï –∫–æ–ø–∏—Ä—É–π –¥–ª–∏–Ω–Ω—ã–µ —Ü–∏—Ç–∞—Ç—ã!"""
        
        try:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –º–µ–Ω–µ–¥–∂–µ—Ä AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–æ–≤ —Å fallback
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": user_prompt}
            ]
            
            try:
                response_text = simple_ai_provider.generate_response(messages, max_tokens=1200)
                logger.info(f"‚úÖ –û—Ç–≤–µ—Ç –æ—Ç AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞ –ø–æ–ª—É—á–µ–Ω")
            except Exception as e:
                logger.error(f"‚ùå –û—à–∏–±–∫–∞ AI –ø—Ä–æ–≤–∞–π–¥–µ—Ä–∞: {e}")
                logger.info(f"üîÑ –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π fallback")
                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –ø—Ä–æ—Å—Ç–æ–π fallback
                fallback_result = simple_fallback.generate_response(question, self.confession_name, relevant_texts)
                return fallback_result
            
            # –ü–æ—Å—Ç–æ–±—Ä–∞–±–æ—Ç–∫–∞
            if "–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:" in response_text:
                response_text = response_text.replace("–ò–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∞—Ü–∏—è:", "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:")
            
            if "–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:" in response_text and "\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:" not in response_text:
                response_text = response_text.replace("–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:", "\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ:")
            
            # –ü—Ä–æ—Å—Ç–∞—è –ø—Ä–æ–≤–µ—Ä–∫–∞ - –µ—Å–ª–∏ –Ω–µ—Ç –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Å—Ç–æ—Ä–æ–∂–Ω—ã–π –æ—Ç–≤–µ—Ç
            if not relevant_texts:
                response_text = f"–í –ø—Ä–∞–≤–æ—Å–ª–∞–≤–Ω—ã—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–∞—Ö –µ—Å—Ç—å –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –ø–æ —ç—Ç–æ–º—É –≤–æ–ø—Ä–æ—Å—É, –Ω–æ –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –æ—Ç–≤–µ—Ç–∞ —Ä–µ–∫–æ–º–µ–Ω–¥—É—é –æ–±—Ä–∞—Ç–∏—Ç—å—Å—è –∫ —Å–≤—è—â–µ–Ω–Ω–∏–∫—É.\n\n–ü—Ä–∏–ª–æ–∂–µ–Ω–∏–µ: –≠—Ç–æ—Ç –≤–æ–ø—Ä–æ—Å —Ç—Ä–µ–±—É–µ—Ç –≥–ª—É–±–æ–∫–æ–≥–æ –∏–∑—É—á–µ–Ω–∏—è —Å–≤—è—â–µ–Ω–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤ –∏ –∫–æ–Ω—Å—É–ª—å—Ç–∞—Ü–∏–∏ —Å –¥—É—Ö–æ–≤–Ω—ã–º –Ω–∞—Å—Ç–∞–≤–Ω–∏–∫–æ–º."
            
            # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–∏–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
            brief_sources = []
            for text in relevant_texts:
                content = text['content']
                if content['type'] == 'orthodox':
                    # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫—É—é –≤–µ—Ä—Å–∏—é –∏—Å—Ç–æ—á–Ω–∏–∫–∞ —Å –ø–æ–ª–Ω—ã–º —Ç–µ–∫—Å—Ç–æ–º –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞
                    brief_content = {
                        'type': 'orthodox',
                        'id': content.get('id'),
                        'book_name': content.get('book_name', ''),
                        'author': content.get('author', ''),
                        'chapter_number': content.get('chapter_number'),
                        'verse_number': content.get('verse_number'),
                        'translation_ru': content.get('translation_ru', '')[:100] + '...' if content.get('translation_ru') else '',
                        'theme': content.get('theme', '–æ–±—â–∏–π'),
                        # –î–æ–±–∞–≤–ª—è–µ–º –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –º–æ–¥–∞–ª—å–Ω–æ–≥–æ –æ–∫–Ω–∞
                        'full_translation_ru': content.get('translation_ru', ''),
                        'full_commentary': content.get('commentary', '')
                    }
                    brief_sources.append({
                        'type': text['content']['type'],
                        'similarity_score': text['similarity_score'],
                        'content': brief_content
                    })
            
            return {
                'response': response_text,
                'sources': brief_sources,
                'confidence': 0.8 if brief_sources else 0.3
            }
            
        except Exception as e:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–∞: {e}")
            return {
                'response': '–ò–∑–≤–∏–Ω–∏—Ç–µ, –ø—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –≤–æ–ø—Ä–æ—Å–∞.',
                'sources': [],
                'confidence': 0.0
            }
    
    def _prepare_context(self, texts: List[Dict[str, Any]]) -> str:
        """–ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è AI"""
        context_parts = []
        
        for text in texts:
            content = text['content']
            if content['type'] == 'orthodox':
                source_info = f"{content['book_name']}"
                if content['author']:
                    source_info += f" ({content['author']})"
                if content['chapter_number'] and content['verse_number']:
                    source_info += f", –≥–ª–∞–≤–∞ {content['chapter_number']}, —Å—Ç–∏—Ö {content['verse_number']}"
                elif content['chapter_number']:
                    source_info += f", –≥–ª–∞–≤–∞ {content['chapter_number']}"
                
                context_parts.append(f"{source_info}: {content['translation_ru'][:400]}...")
        
        return "\n".join(context_parts)
    
    def _calculate_similarity(self, question: str, text: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä—è–µ—Ç —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å —Ç–µ–∫—Å—Ç–∞"""
        if not text:
            return False
        
        # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        import re
        question_clean = re.sub(r'[^\w\s]', ' ', question.lower())
        text_clean = re.sub(r'[^\w\s]', ' ', text.lower())
        
        question_words = set(question_clean.split())
        text_words = set(text_clean.split())
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–µ—Ä–µ—Å–µ—á–µ–Ω–∏–µ –∫–ª—é—á–µ–≤—ã—Ö —Å–ª–æ–≤
        common_words = question_words.intersection(text_words)
        
        # –¢–∞–∫–∂–µ –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è –¥–ª—è –≤–∞–∂–Ω—ã—Ö —Å–ª–æ–≤
        important_words = ['–±–æ–≥', '–∞–ª–ª–∞—Ö', '–º–æ–ª–∏—Ç–≤–∞', '–≤–µ—Ä–∞', '–∏—Å–ª–∞–º', '–∫–æ—Ä–∞–Ω', '—Ö–∞–¥–∏—Å', 
                          '—Å–µ–º—å—è', '—Å–µ–º–µ–π–Ω—ã–π', '–ø—Ä–æ–±–ª–µ–º–∞', '—Ä–µ—à–∏—Ç—å', '–Ω–∞—Å–∏–ª–∏–µ', '–º–∏—Ä', '—Å–ø–æ–∫–æ–π—Å—Ç–≤–∏–µ', '—Ç–µ—Ä–ø–µ–Ω–∏–µ',
                          '–ª—é–±–æ–≤—å', '—É–≤–∞–∂–µ–Ω–∏–µ', '–ø—Ä–æ—â–µ–Ω–∏–µ', '–¥–æ–±—Ä–æ—Ç–∞', '–º–∏–ª–æ—Å–µ—Ä–¥–∏–µ', '—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å']
        for word in important_words:
            if word in question_clean and word in text_clean:
                return True
        
        return len(common_words) >= 1  # –°–Ω–∏–∂–∞–µ–º —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–µ –¥–æ 1 —Å–ª–æ–≤–∞
    
    def _calculate_similarity_score(self, question: str, text: str) -> float:
        """–£–õ–¨–¢–†–ê-–ü–†–û–°–¢–û–ô –∞–ª–≥–æ—Ä–∏—Ç–º –ø–æ–∏—Å–∫–∞ - –í–°–ï–ì–î–ê –ù–ê–•–û–î–ò–¢ –ò–°–¢–û–ß–ù–ò–ö–ò"""
        if not text:
            return 0.0
        
        # –û—á–∏—â–∞–µ–º —Å–ª–æ–≤–∞ –æ—Ç –∑–Ω–∞–∫–æ–≤ –ø—Ä–µ–ø–∏–Ω–∞–Ω–∏—è
        import re
        question_clean = re.sub(r'[^\w\s]', ' ', question.lower())
        text_clean = re.sub(r'[^\w\s]', ' ', text.lower())
        
        question_words = set(question_clean.split())
        text_words = set(text_clean.split())
        
        if not question_words or not text_words:
            return 0.0
        
        # –£–õ–¨–¢–†–ê-–ü–†–û–°–¢–û–ô –ø–æ–∏—Å–∫ - –µ—Å–ª–∏ –µ—Å—Ç—å –õ–Æ–ë–û–ï —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ —Å–ª–æ–≤
        intersection = len(question_words.intersection(text_words))
        if intersection > 0:
            return 0.8  # –í–´–°–û–ö–ê–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞ –ª—é–±–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        
        # –ï—Å–ª–∏ –Ω–µ—Ç –ø—Ä—è–º—ã—Ö —Å–æ–≤–ø–∞–¥–µ–Ω–∏–π, –∏—â–µ–º —á–∞—Å—Ç–∏—á–Ω—ã–µ
        for q_word in question_words:
            for t_word in text_words:
                if len(q_word) > 2 and len(t_word) > 2:
                    if q_word in t_word or t_word in q_word:
                        return 0.6  # –°–†–ï–î–ù–Ø–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –∑–∞ —á–∞—Å—Ç–∏—á–Ω–æ–µ —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ
        
        # –ï—Å–ª–∏ –≤–æ–æ–±—â–µ –Ω–∏—á–µ–≥–æ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –Ω–æ —ç—Ç–æ —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã–π —Ç–µ–∫—Å—Ç - –¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score
        religious_words = ['–±–æ–≥', '–∞–ª–ª–∞—Ö', '–º–æ–ª–∏—Ç–≤–∞', '–≤–µ—Ä–∞', '–∏—Å–ª–∞–º', '–∫–æ—Ä–∞–Ω', '—Ö–∞–¥–∏—Å', '–ø—Ä–æ—Ä–æ–∫', '–º—É—Ö–∞–º–º–∞–¥', '–∏–∏—Å—É—Å', '—Ö—Ä–∏—Å—Ç–æ—Å', '–±–∏–±–ª–∏—è', '–∏—Å—Ç–∏–Ω–∞', '–ø—Ä–∞–≤–¥–∞', '—Å–ø—Ä–∞–≤–µ–¥–ª–∏–≤–æ—Å—Ç—å', '–ª—é–±–æ–≤—å', '–º–∏—Ä', '—Å–µ–º—å—è']
        text_religious = any(word in text_clean for word in religious_words)
        
        if text_religious:
            return 0.3  # –ú–ò–ù–ò–ú–ê–õ–¨–ù–ê–Ø —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω–æ—Å—Ç—å –¥–ª—è —Ä–µ–ª–∏–≥–∏–æ–∑–Ω—ã—Ö —Ç–µ–∫—Å—Ç–æ–≤
        
        # –í –∫—Ä–∞–π–Ω–µ–º —Å–ª—É—á–∞–µ - –¥–∞–µ–º –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–π score –≤—Å–µ–º —Ç–µ–∫—Å—Ç–∞–º
        return 0.1


class ConfessionAgentFactory:
    """–§–∞–±—Ä–∏–∫–∞ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∞–≥–µ–Ω—Ç–æ–≤ –∫–æ–Ω—Ñ–µ—Å—Å–∏–π"""
    
    @staticmethod
    def create_agent(confession: str, db: Session) -> BaseConfessionAgent:
        """–°–æ–∑–¥–∞–µ—Ç –∞–≥–µ–Ω—Ç–∞ –¥–ª—è —É–∫–∞–∑–∞–Ω–Ω–æ–π –∫–æ–Ω—Ñ–µ—Å—Å–∏–∏"""
        if confession == 'sunni':
            return SunniAgent(confession, db)
        elif confession == 'shia':
            return ShiaAgent(confession, db)
        elif confession == 'orthodox':
            return OrthodoxAgent(confession, db)
        else:
            raise ValueError(f"–ù–µ–ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º–∞—è –∫–æ–Ω—Ñ–µ—Å—Å–∏—è: {confession}")

#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞ HTML —Ñ–∞–π–ª–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ –ö–æ—Ä–∞–Ω–∞
"""

import sys
import os
import re
from pathlib import Path
from bs4 import BeautifulSoup
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class QuranHTMLParser:
    """–ü–∞—Ä—Å–µ—Ä HTML —Ñ–∞–π–ª–∞ —Å –ø–µ—Ä–µ–≤–æ–¥–∞–º–∏ –ö–æ—Ä–∞–Ω–∞"""
    
    def __init__(self, html_file_path: str):
        self.html_file_path = html_file_path
        self.verses = []
    
    def parse(self):
        """–ü–∞—Ä—Å–∏–Ω–≥ HTML —Ñ–∞–π–ª–∞"""
        try:
            logger.info(f"üìñ –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª: {self.html_file_path}")
            
            with open(self.html_file_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º BeautifulSoup –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞
            soup = BeautifulSoup(content, 'html.parser')
            
            # –ò—â–µ–º –∞—è—Ç—ã –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º
            self._parse_verses_by_patterns(soup)
            
            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ {len(self.verses)} –∞—è—Ç–æ–≤")
            return self.verses
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞: {e}")
            return []
    
    def _parse_verses_by_patterns(self, soup):
        """–ü–∞—Ä—Å–∏–Ω–≥ –∞—è—Ç–æ–≤ –ø–æ —Ä–∞–∑–ª–∏—á–Ω—ã–º –ø–∞—Ç—Ç–µ—Ä–Ω–∞–º"""
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 1: –ü–æ–∏—Å–∫ –ø–æ –∫–ª–∞—Å—Å–∞–º
        verse_elements = soup.find_all(['div', 'p', 'span'], class_=re.compile(r'verse|ayat|ayah', re.I))
        
        for element in verse_elements:
            verse_data = self._extract_verse_data(element)
            if verse_data:
                self.verses.append(verse_data)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 2: –ü–æ–∏—Å–∫ –ø–æ —Ç–µ–∫—Å—Ç—É —Å –Ω–æ–º–µ—Ä–∞–º–∏ –∞—è—Ç–æ–≤
        text_pattern = r'(\d+):(\d+)\s*(.*?)(?=\d+:\d+|$)'
        text_matches = re.findall(text_pattern, soup.get_text(), re.DOTALL)
        
        for surah_num, verse_num, text in text_matches:
            if text.strip():
                verse_data = {
                    'surah_number': int(surah_num),
                    'verse_number': int(verse_num),
                    'arabic_text': text.strip(),
                    'translation_ru': text.strip(),
                    'theme': '–æ–±—â–∏–π'
                }
                self.verses.append(verse_data)
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω 3: –ü–æ–∏—Å–∫ –∞—Ä–∞–±—Å–∫–æ–≥–æ —Ç–µ–∫—Å—Ç–∞
        arabic_pattern = r'[\u0600-\u06FF\u0750-\u077F\u08A0-\u08FF\uFB50-\uFDFF\uFE70-\uFEFF]+'
        arabic_matches = re.findall(arabic_pattern, soup.get_text())
        
        for i, arabic_text in enumerate(arabic_matches[:50]):  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–ª—è —Ç–µ—Å—Ç–∞
            if len(arabic_text.strip()) > 10:  # –ú–∏–Ω–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞
                verse_data = {
                    'surah_number': 1,
                    'verse_number': i + 1,
                    'arabic_text': arabic_text.strip(),
                    'translation_ru': f"–ü–µ—Ä–µ–≤–æ–¥ –∞—è—Ç–∞ {i + 1}",
                    'theme': '–æ–±—â–∏–π'
                }
                self.verses.append(verse_data)
    
    def _extract_verse_data(self, element):
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ –¥–∞–Ω–Ω—ã—Ö –∞—è—Ç–∞ –∏–∑ —ç–ª–µ–º–µ–Ω—Ç–∞"""
        try:
            text = element.get_text().strip()
            
            # –ò—â–µ–º –Ω–æ–º–µ—Ä —Å—É—Ä—ã –∏ –∞—è—Ç–∞
            surah_verse_match = re.search(r'(\d+):(\d+)', text)
            if surah_verse_match:
                surah_num = int(surah_verse_match.group(1))
                verse_num = int(surah_verse_match.group(2))
                
                # –£–±–∏—Ä–∞–µ–º –Ω–æ–º–µ—Ä –∏–∑ —Ç–µ–∫—Å—Ç–∞
                clean_text = re.sub(r'\d+:\d+\s*', '', text).strip()
                
                return {
                    'surah_number': surah_num,
                    'verse_number': verse_num,
                    'arabic_text': clean_text,
                    'translation_ru': clean_text,
                    'theme': '–æ–±—â–∏–π'
                }
            
            return None
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –∏–∑–≤–ª–µ—á–µ–Ω–∏—è –¥–∞–Ω–Ω—ã—Ö: {e}")
            return None
    
    def save_to_json(self, output_file: str):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤ JSON —Ñ–∞–π–ª"""
        try:
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(self.verses, f, ensure_ascii=False, indent=2)
            
            logger.info(f"‚úÖ –î–∞–Ω–Ω—ã–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ {output_file}")
            
        except Exception as e:
            logger.error(f"‚ùå –û—à–∏–±–∫–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è: {e}")

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è"""
    try:
        html_file = "/Users/kamong/telegram_ai_assistant/legacy_m/data/–ö–æ—Ä–∞–Ω. –í—Å–µ –ø–µ—Ä–µ–≤–æ–¥—ã.html"
        
        if not os.path.exists(html_file):
            logger.error(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {html_file}")
            return
        
        # –°–æ–∑–¥–∞–µ–º –ø–∞—Ä—Å–µ—Ä
        parser = QuranHTMLParser(html_file)
        
        # –ü–∞—Ä—Å–∏–º —Ñ–∞–π–ª
        verses = parser.parse()
        
        if verses:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ JSON
            output_file = "/Users/kamong/telegram_ai_assistant/legacy_m/data/parsed_quran.json"
            parser.save_to_json(output_file)
            
            logger.info(f"‚úÖ –ü–∞—Ä—Å–∏–Ω–≥ –∑–∞–≤–µ—Ä—à–µ–Ω. –ù–∞–π–¥–µ–Ω–æ {len(verses)} –∞—è—Ç–æ–≤")
        else:
            logger.warning("‚ö†Ô∏è –ê—è—Ç—ã –Ω–µ –Ω–∞–π–¥–µ–Ω—ã")
        
    except Exception as e:
        logger.error(f"‚ùå –û—à–∏–±–∫–∞: {e}")

if __name__ == "__main__":
    main()
